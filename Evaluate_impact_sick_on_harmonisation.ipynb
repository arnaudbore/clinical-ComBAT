{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTS and UTILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print(\"hi\")\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import re\n",
    "import numpy as np\n",
    "import json\n",
    "import csv\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "from robust_evaluation_tools.robust_utils import get_site, get_metric, get_disease, add_nb_patients_and_diseased\n",
    "from robust_evaluation_tools.robust_harmonization import fit, apply, QC, compare_with_compilation \n",
    "from robust_evaluation_tools.synthectic_sites_generations import generate_sites\n",
    "\n",
    "SYNTHETIC_SITES = \"IMPACT_SICK/SYNTHETIC_SITES\"\n",
    "\n",
    "MAINFOLDER = \"IMPACT_SICK/RESULTS\"\n",
    "\n",
    "ANALYSISFOLDER = \"IMPACT_SICK/ANALYSIS\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HARMONIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def harmonize(f_train,f_test, ref_data_file, metric, harmonizartion_method,  directory, robust, rwp,hc):\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    \n",
    "    # Fit the model\n",
    "    output_model_filename = fit(f_train, ref_data_file, metric, harmonizartion_method, robust, rwp, directory, hc,)\n",
    "    # Apply the model\n",
    "    output_filename = apply(f_test, output_model_filename, metric, harmonizartion_method, robust, rwp, directory)\n",
    "    \n",
    "    # Perform quality control\n",
    "    dists, bundle_names = QC(ref_data_file, output_filename, output_model_filename)\n",
    "    dists_df = pd.DataFrame([dists], columns=bundle_names)\n",
    "    dists_df['site'] = get_site(f_train)\n",
    "    dists_df['metric'] = get_metric(f_train)\n",
    "    dists_df['disease'] = get_disease(f_train)\n",
    "\n",
    "    mea = compare_with_compilation(pd.read_csv(output_filename))\n",
    "    mea['site'] = get_site(f_train)\n",
    "    mea['metric'] = get_metric(f_train)\n",
    "    mea['disease'] = get_disease(f_train)\n",
    "    \n",
    "    return[dists_df, mea]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_site(f_train,f_test,ref_data_file,metric,harmonizartion_method, directory):\n",
    "    # 4 harmonization\n",
    "    harmonization_hc = harmonize(f_train, f_test, ref_data_file, metric, harmonizartion_method, os.path.join(directory, \"hc\"), \"No\", False, True)\n",
    "    harmonization_sick = harmonize(f_train, f_test,ref_data_file, metric, harmonizartion_method, os.path.join(directory, \"sick\"), \"No\", False, False)\n",
    "\n",
    "    distances_combined = pd.concat([harmonization_hc[0], harmonization_sick[0]], ignore_index=True)\n",
    "    distances_combined['method'] = ['hc', 'no_robust']\n",
    "\n",
    "    # Combine MEA in a single DataFrame\n",
    "    mea_combined = pd.concat([harmonization_hc[1], harmonization_sick[1]], ignore_index=True)\n",
    "    mea_combined['method'] = ['hc', 'no_robust']\n",
    "\n",
    "\n",
    "    #TODO bundles et analyze outliers\n",
    "    return distances_combined, mea_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "#Analyse Method\n",
    "def analyse_method(sample_sizes, disease_ratios, num_tests,metrics, harmonizartion_method, main_directory, SYNTHETIC_SITES_VERSION):\n",
    "    # Split the data into training and testing sets\n",
    "    directory_site = os.path.join(SYNTHETIC_SITES ,SYNTHETIC_SITES_VERSION)\n",
    "    # Initialize DataFrames to store the results\n",
    "    dists_compilation = pd.DataFrame()\n",
    "    mea_compilation = pd.DataFrame()\n",
    "    for disease in [d for d in sorted(os.listdir(directory_site)) if os.path.isdir(os.path.join(directory_site, d))]:\n",
    "        directory = os.path.join(main_directory, disease)\n",
    "        for sample_size in sample_sizes:\n",
    "            for disease_ratio in disease_ratios:        \n",
    "                sizeDir = os.path.join(directory, f\"{sample_size}_{int(disease_ratio*100)}\")\n",
    "                sizeDir_site = os.path.join(directory_site,disease, f\"{sample_size}_{int(disease_ratio*100)}\")\n",
    "                for i in range(num_tests):\n",
    "                    for metric in metrics:\n",
    "                        tempDir = os.path.join(sizeDir, f\"{i}\")\n",
    "                        tempDir_site = os.path.join(sizeDir_site, f\"{i}\")\n",
    "                        os.makedirs(tempDir, exist_ok=True)\n",
    "\n",
    "                        train_file_name = f\"train_{sample_size}_{int(disease_ratio*100)}_{i}_{metric}.csv\"\n",
    "                        test_file_name = f\"test_{sample_size}_{int(disease_ratio*100)}_{i}_{metric}.csv\"\n",
    "                        \n",
    "                        # Sauvegarder l'échantillon dans un fichier temporaire\n",
    "                        temp_file = os.path.join(tempDir_site,train_file_name )\n",
    "                        train_df = pd.read_csv(temp_file)\n",
    "                        train_df.to_csv(os.path.join(tempDir,train_file_name ), index=False)\n",
    "\n",
    "                        test_file = os.path.join(tempDir_site, test_file_name)\n",
    "                        test_df = pd.read_csv(test_file)\n",
    "                        test_df.to_csv(os.path.join(tempDir,test_file_name ), index=False)\n",
    "\n",
    "                        ref_data_file = os.path.join('DONNES','CamCAN', f\"CamCAN.{metric}.raw.csv.gz\")\n",
    "                    \n",
    "                        # Analyser le site pour le nouvel échantillon\n",
    "                        dists_analyze, mea_analyze= analyse_site(temp_file, test_file, ref_data_file,metric,harmonizartion_method, tempDir)\n",
    "                        dists_compilation = pd.concat([dists_compilation, dists_analyze])\n",
    "                        mea_compilation = pd.concat([mea_compilation, mea_analyze])               \n",
    "    dists_compilation.to_csv(os.path.join(directory, \"dists_compilation.csv\"), index=False)\n",
    "    mea_compilation.to_csv(os.path.join(directory, \"mea_compilation.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXECUTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "harmonizartion_method= \"classic\"\n",
    "\n",
    "SYNTHETIC_SITES_VERSION = \"v1\"\n",
    "raw_directory = os.path.join('DONNES', 'COMPILATIONS')\n",
    "\n",
    "\n",
    "sample_sizes = [40]  # Différentes tailles d'échantillon\n",
    "disease_ratios = [0.1, 0.3, 0.5, 0.7]  # Différents pourcentages de malades\n",
    "#sample_sizes = [150, 300]  # Différentes tailles d'échantillon\n",
    "#disease_ratios = [0.3]  # Différents pourcentages de malades\n",
    "num_tests = 8  # Nombre de tests à effectuer pour chaque combinaison\n",
    "camcan_data = pd.read_csv('DONNES/CamCAN_combination_all_metrics.csv.gz')\n",
    "metrics = [\"ad\", \"adt\", \"afd\", \"fa\", \"fat\", \"fw\", \"md\", \"mdt\", \"rd\", \"rdt\"]\n",
    "\n",
    "\n",
    "for disease in [d for d in sorted(os.listdir(raw_directory)) if os.path.isdir(os.path.join(raw_directory, d))]:\n",
    "    data_path = os.path.join(raw_directory,f'{disease}_combination_all_metrics.csv.gz')\n",
    "    data = pd.read_csv(data_path)\n",
    "    num_unique_sid_hc = data[data['disease'] == 'HC']['sid'].nunique()\n",
    "    directory_site = os.path.join(SYNTHETIC_SITES ,SYNTHETIC_SITES_VERSION, disease)\n",
    "    #generate_sites(sample_sizes, disease_ratios, num_tests, directory_site, data_path, disease=None)\n",
    "\n",
    "#analyse_method(sample_sizes, disease_ratios, num_tests, metrics,harmonizartion_method, MAINFOLDER, SYNTHETIC_SITES_VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANALYSYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Moyenne par site\n",
    "# # Nothing really interesting so far\n",
    "\n",
    "# directory = ANALYSISFOLDER\n",
    "# os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "# dists_compilation['site'] = dists_compilation['site'].str.rsplit('_', n=1).str[0]\n",
    "# metrics_compilation['site'] = metrics_compilation['site'].str.rsplit('_', n=1).str[0]\n",
    "\n",
    "# # Display the means by site\n",
    "# dists_means_by_site = dists_compilation.groupby(['site','method']).mean().reset_index()\n",
    "# metrics_means_by_site = metrics_compilation.groupby(['site', 'metric']).mean().reset_index()\n",
    "\n",
    "# metrics_means_by_site.to_csv(os.path.join(directory, \"metrics_compilation_mean.csv\"), index=False)\n",
    "# dists_means_by_site.to_csv(os.path.join(directory, \"dists_compilation_mean.csv\"), index=False)\n",
    "# print(\"FINI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Exemple d'utilisation\n",
    "# precision_df = calculate_precision_by_bundle(pd.read_csv(os.path.join(MAINFOLDER, robust_method, \"metrics_compilation.csv\")))\n",
    "# precision_df = precision_df.sort_values(by='precision', ascending=False)\n",
    "# precision_df.to_csv(os.path.join(directory, \"metrics_per_bundle.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision_df = precision_df.sort_values(by='precision', ascending=False)\n",
    "# precision_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision_df = precision_df.sort_values(by='f1_score', ascending=False)\n",
    "# precision_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATION BOX PLOT POUR DISTANCES\n",
    "def plot_bundle(df, sample_size, disease, metric, directory):\n",
    "    \"\"\"\n",
    "    Crée un graphique pour chaque bundle dans le DataFrame donné.\n",
    "    L'axe des X représente le nombre de patients et l'axe des Y représente la moyenne de la colonne du bundle.\n",
    "    La courbe inclut une zone indiquant l'écart-type (std).\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Le DataFrame contenant les données.\n",
    "    bundle_column (str): Le nom de la colonne du bundle à utiliser pour le graphique.\n",
    "    \"\"\"\n",
    "    directory = os.path.join(directory, \"DISTANCES_PLOTS\", disease, metric, str(sample_size))\n",
    "    df = df[df['num_patients'] == sample_size]\n",
    "    df = df[df['disease'] == disease]\n",
    "    df = df[df['metric'] == metric]\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    \n",
    "    for bundle_column in df.columns:\n",
    "        if bundle_column in ['site','method','num_patients','disease_ratio','num_diseased', 'metric', 'disease']:\n",
    "            continue # Skip non-numeric columns\n",
    "        bundle_df = df[[bundle_column, 'site', 'method','num_patients','disease_ratio','num_diseased']].copy()\n",
    "        methods = [\"hc\", \"no_robust\"]\n",
    "        colors = ['green', 'red']\n",
    "        \n",
    "        plt.figure(figsize=(10, 5))\n",
    "        width = 0.2  # the width of the bars\n",
    "        x = np.arange(len(bundle_df['disease_ratio'].unique()))  # the label locations\n",
    "        fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "        for i, (method, color) in enumerate(zip(methods, colors)):\n",
    "            method_df = bundle_df[bundle_df['method'] == method]\n",
    "            data = [method_df[method_df['disease_ratio'] == patients][bundle_column].values \n",
    "                    for patients in bundle_df['disease_ratio'].unique()]\n",
    "            \n",
    "            # Ensure there is data for each num_patients\n",
    "            if any(len(d) > 0 for d in data):\n",
    "                positions = x + i * width  # Shift positions for each method\n",
    "                ax.boxplot(data, positions=positions, widths=0.15, patch_artist=True, \n",
    "                        boxprops=dict(facecolor=color, color=color),\n",
    "                        medianprops=dict(color='black'))\n",
    "                \n",
    "        ax.set_xlabel('Prct de patients malades')\n",
    "        ax.set_ylabel('Distance de Battacharyya')\n",
    "        ax.set_title(f'Boxplots pour le bundle: {bundle_column} avec {sample_size} de malades')\n",
    "        ax.set_xticks(x + width * (len(methods) - 1) / 2)\n",
    "        ax.set_xticklabels(bundle_df['disease_ratio'].unique())\n",
    "        ax.legend(handles=[plt.Line2D([0], [0], color=color, lw=2, label=f'Method: {method}') for method, color in zip(methods, colors)])\n",
    "        plt.savefig(os.path.join(directory, f'{bundle_column}_boxplot.png'))\n",
    "        plt.close()\n",
    "diseases = [\"AD\", \"ADHD\", \"BIP\", \"MCI\", \"SCHZ\", \"TBI\"]\n",
    "# Exemple d'utilisation\n",
    "distances_df = pd.read_csv(os.path.join(MAINFOLDER, \"dists_compilation.csv\"))\n",
    "add_nb_patients_and_diseased(distances_df)\n",
    "sample_sizes = [40]\n",
    "for disease in diseases:\n",
    "    for sample_size in sample_sizes:\n",
    "        for metric in metrics:\n",
    "            plot_bundle(distances_df, sample_size, disease, metric, ANALYSISFOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 52\u001b[0m\n\u001b[1;32m     50\u001b[0m diseases \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAD\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mADHD\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBIP\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMCI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSCHZ\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTBI\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Exemple d'utilisation\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m mea_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(MAINFOLDER, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmea_compilation.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     53\u001b[0m add_nb_patients_and_diseased(mea_df)\n\u001b[1;32m     54\u001b[0m sample_sizes \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m40\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# CREATION BOX PLOT POUR MEA\n",
    "def plot_mea(df, sample_size, disease, metric, directory):\n",
    "    \"\"\"\n",
    "    Crée un graphique pour chaque bundle dans le DataFrame donné.\n",
    "    L'axe des X représente le nombre de patients et l'axe des Y représente la moyenne de la colonne du bundle.\n",
    "    La courbe inclut une zone indiquant l'écart-type (std).\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Le DataFrame contenant les données.\n",
    "    bundle_column (str): Le nom de la colonne du bundle à utiliser pour le graphique.\n",
    "    \"\"\"\n",
    "    directory = os.path.join(directory, \"MEA_PLOTS\", disease, metric, str(sample_size))\n",
    "    df = df[df['num_patients'] == sample_size]\n",
    "    df = df[df['disease'] == disease]\n",
    "    df = df[df['metric'] == metric]\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    \n",
    "    for bundle_column in df.columns:\n",
    "        if bundle_column in ['site','method','num_patients','disease_ratio','num_diseased', 'metric', 'disease']:\n",
    "            continue # Skip non-numeric columns\n",
    "        bundle_df = df[[bundle_column, 'site', 'method','num_patients','disease_ratio','num_diseased']].copy()\n",
    "        methods = [\"hc\", \"no_robust\"]\n",
    "        colors = ['green', 'red']\n",
    "        \n",
    "        plt.figure(figsize=(10, 5))\n",
    "        width = 0.2  # the width of the bars\n",
    "        x = np.arange(len(bundle_df['disease_ratio'].unique()))  # the label locations\n",
    "        fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "        for i, (method, color) in enumerate(zip(methods, colors)):\n",
    "            method_df = bundle_df[bundle_df['method'] == method]\n",
    "            data = [method_df[method_df['disease_ratio'] == patients][bundle_column].values \n",
    "                    for patients in bundle_df['disease_ratio'].unique()]\n",
    "            \n",
    "            # Ensure there is data for each num_patients\n",
    "            if any(len(d) > 0 for d in data):\n",
    "                positions = x + i * width  # Shift positions for each method\n",
    "                ax.boxplot(data, positions=positions, widths=0.15, patch_artist=True, \n",
    "                        boxprops=dict(facecolor=color, color=color),\n",
    "                        medianprops=dict(color='black'))\n",
    "                \n",
    "        ax.set_xlabel('Prct de patients malades')\n",
    "        ax.set_ylabel('MEA')\n",
    "        ax.set_title(f'Boxplots pour le bundle: {bundle_column} avec {sample_size} de malades')\n",
    "        ax.set_xticks(x + width * (len(methods) - 1) / 2)\n",
    "        ax.set_xticklabels(bundle_df['disease_ratio'].unique())\n",
    "        ax.legend(handles=[plt.Line2D([0], [0], color=color, lw=2, label=f'Method: {method}') for method, color in zip(methods, colors)])\n",
    "        plt.savefig(os.path.join(directory, f'{bundle_column}_boxplot.png'))\n",
    "        plt.close()\n",
    "diseases = [\"AD\", \"ADHD\", \"BIP\", \"MCI\", \"SCHZ\", \"TBI\"]\n",
    "# Exemple d'utilisation\n",
    "mea_df = pd.read_csv(os.path.join(MAINFOLDER, \"mea_compilation.csv\"))\n",
    "add_nb_patients_and_diseased(mea_df)\n",
    "sample_sizes = [40]\n",
    "for disease in diseases:\n",
    "    for sample_size in sample_sizes:\n",
    "        for metric in metrics:\n",
    "            plot_mea(mea_df, sample_size, disease, metric, ANALYSISFOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disease</th>\n",
       "      <th>highest_bhattacharyya</th>\n",
       "      <th>lowest_bhattacharyya</th>\n",
       "      <th>highest_kl</th>\n",
       "      <th>lowest_kl</th>\n",
       "      <th>highest_euclidean</th>\n",
       "      <th>lowest_euclidean</th>\n",
       "      <th>highest_mahalanobis</th>\n",
       "      <th>lowest_mahalanobis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AD</td>\n",
       "      <td>fw</td>\n",
       "      <td>afd</td>\n",
       "      <td>mdt</td>\n",
       "      <td>afd</td>\n",
       "      <td>fw</td>\n",
       "      <td>rdt</td>\n",
       "      <td>fw</td>\n",
       "      <td>afd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADHD</td>\n",
       "      <td>adt</td>\n",
       "      <td>fw</td>\n",
       "      <td>adt</td>\n",
       "      <td>fw</td>\n",
       "      <td>afd</td>\n",
       "      <td>mdt</td>\n",
       "      <td>afd</td>\n",
       "      <td>fw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BIP</td>\n",
       "      <td>adt</td>\n",
       "      <td>afd</td>\n",
       "      <td>adt</td>\n",
       "      <td>fw</td>\n",
       "      <td>fat</td>\n",
       "      <td>mdt</td>\n",
       "      <td>fat</td>\n",
       "      <td>mdt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MCI</td>\n",
       "      <td>fw</td>\n",
       "      <td>adt</td>\n",
       "      <td>adt</td>\n",
       "      <td>afd</td>\n",
       "      <td>fw</td>\n",
       "      <td>rdt</td>\n",
       "      <td>fw</td>\n",
       "      <td>afd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SCHZ</td>\n",
       "      <td>fat</td>\n",
       "      <td>md</td>\n",
       "      <td>adt</td>\n",
       "      <td>fw</td>\n",
       "      <td>fat</td>\n",
       "      <td>mdt</td>\n",
       "      <td>fa</td>\n",
       "      <td>mdt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TBI</td>\n",
       "      <td>afd</td>\n",
       "      <td>ad</td>\n",
       "      <td>afd</td>\n",
       "      <td>fa</td>\n",
       "      <td>afd</td>\n",
       "      <td>ad</td>\n",
       "      <td>afd</td>\n",
       "      <td>ad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  disease highest_bhattacharyya lowest_bhattacharyya highest_kl lowest_kl  \\\n",
       "0      AD                    fw                  afd        mdt       afd   \n",
       "1    ADHD                   adt                   fw        adt        fw   \n",
       "2     BIP                   adt                  afd        adt        fw   \n",
       "3     MCI                    fw                  adt        adt       afd   \n",
       "4    SCHZ                   fat                   md        adt        fw   \n",
       "5     TBI                   afd                   ad        afd        fa   \n",
       "\n",
       "  highest_euclidean lowest_euclidean highest_mahalanobis lowest_mahalanobis  \n",
       "0                fw              rdt                  fw                afd  \n",
       "1               afd              mdt                 afd                 fw  \n",
       "2               fat              mdt                 fat                mdt  \n",
       "3                fw              rdt                  fw                afd  \n",
       "4               fat              mdt                  fa                mdt  \n",
       "5               afd               ad                 afd                 ad  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_path = 'RESULTS/DISTRIBUTION_RESULTS/distance_metrics_results.csv'\n",
    "distance_metrics_results = pd.read_csv(output_path)\n",
    "\n",
    "average_results = distance_metrics_results.groupby(['disease', 'metric']).mean(numeric_only=True).reset_index()\n",
    "average_results\n",
    "highest_lowest_metrics = average_results.groupby('disease').agg(\n",
    "    highest_bhattacharyya=('bhattacharyya_distance', lambda x: average_results.loc[x.idxmax(), 'metric']),\n",
    "    lowest_bhattacharyya=('bhattacharyya_distance', lambda x: average_results.loc[x.idxmin(), 'metric']),\n",
    "    highest_kl=('kl_divergence', lambda x: average_results.loc[x.idxmax(), 'metric']),\n",
    "    lowest_kl=('kl_divergence', lambda x: average_results.loc[x.idxmin(), 'metric']),\n",
    "    highest_euclidean=('euclidean_distance', lambda x: average_results.loc[x.idxmax(), 'metric']),\n",
    "    lowest_euclidean=('euclidean_distance', lambda x: average_results.loc[x.idxmin(), 'metric']),\n",
    "    highest_mahalanobis=('mahalanobis_distance', lambda x: average_results.loc[x.idxmax(), 'metric']),\n",
    "    lowest_mahalanobis=('mahalanobis_distance', lambda x: average_results.loc[x.idxmin(), 'metric'])\n",
    ").reset_index()\n",
    "\n",
    "highest_lowest_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disease</th>\n",
       "      <th>highest_bhattacharyya</th>\n",
       "      <th>lowest_bhattacharyya</th>\n",
       "      <th>highest_kl</th>\n",
       "      <th>lowest_kl</th>\n",
       "      <th>highest_euclidean</th>\n",
       "      <th>lowest_euclidean</th>\n",
       "      <th>highest_mahalanobis</th>\n",
       "      <th>lowest_mahalanobis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AD</td>\n",
       "      <td>fw_mni_UF_L</td>\n",
       "      <td>fa_mni_ICP_R</td>\n",
       "      <td>rd_mni_CST_L</td>\n",
       "      <td>afd_mni_AC</td>\n",
       "      <td>fw_mni_F_L_R</td>\n",
       "      <td>rdt_mni_ICP_R</td>\n",
       "      <td>fw_mni_AC</td>\n",
       "      <td>afd_mni_MdLF_L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADHD</td>\n",
       "      <td>fa_mni_ICP_L</td>\n",
       "      <td>fa_mni_OPT_R</td>\n",
       "      <td>mdt_mni_C_R</td>\n",
       "      <td>fw_mni_MdLF_R</td>\n",
       "      <td>afd_mni_ICP_L</td>\n",
       "      <td>mdt_mni_AF_L</td>\n",
       "      <td>afd_mni_MCP</td>\n",
       "      <td>fa_mni_OPT_R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BIP</td>\n",
       "      <td>fw_mni_ICP_R</td>\n",
       "      <td>rd_mni_F_L_R</td>\n",
       "      <td>adt_mni_AF_L</td>\n",
       "      <td>afd_mni_UF_R</td>\n",
       "      <td>fat_mni_F_L_R</td>\n",
       "      <td>mdt_mni_CCMid</td>\n",
       "      <td>fat_mni_CCMid</td>\n",
       "      <td>mdt_mni_ICP_R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MCI</td>\n",
       "      <td>fw_mni_ICP_R</td>\n",
       "      <td>afd_mni_ICP_R</td>\n",
       "      <td>adt_mni_PPT_L</td>\n",
       "      <td>fat_mni_AF_L</td>\n",
       "      <td>fw_mni_F_L_R</td>\n",
       "      <td>adt_mni_SLF_R</td>\n",
       "      <td>fw_mni_UF_L</td>\n",
       "      <td>afd_mni_FPT_L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SCHZ</td>\n",
       "      <td>fat_mni_CST_R</td>\n",
       "      <td>mdt_mni_CST_L</td>\n",
       "      <td>adt_mni_AF_R</td>\n",
       "      <td>fat_mni_MCP</td>\n",
       "      <td>fat_mni_IFOF_R</td>\n",
       "      <td>mdt_mni_IIT_mask_skeletonFA</td>\n",
       "      <td>fa_mni_IFOF_R</td>\n",
       "      <td>mdt_mni_IIT_mask_skeletonFA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TBI</td>\n",
       "      <td>afd_mni_SLF_R</td>\n",
       "      <td>ad_mni_FPT_R</td>\n",
       "      <td>afd_mni_OR_L</td>\n",
       "      <td>fa_mni_OPT_R</td>\n",
       "      <td>afd_mni_VOF_L</td>\n",
       "      <td>ad_mni_CST_R</td>\n",
       "      <td>afd_mni_IFOF_L</td>\n",
       "      <td>ad_mni_CST_R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  disease highest_bhattacharyya lowest_bhattacharyya     highest_kl  \\\n",
       "0      AD           fw_mni_UF_L         fa_mni_ICP_R   rd_mni_CST_L   \n",
       "1    ADHD          fa_mni_ICP_L         fa_mni_OPT_R    mdt_mni_C_R   \n",
       "2     BIP          fw_mni_ICP_R         rd_mni_F_L_R   adt_mni_AF_L   \n",
       "3     MCI          fw_mni_ICP_R        afd_mni_ICP_R  adt_mni_PPT_L   \n",
       "4    SCHZ         fat_mni_CST_R        mdt_mni_CST_L   adt_mni_AF_R   \n",
       "5     TBI         afd_mni_SLF_R         ad_mni_FPT_R   afd_mni_OR_L   \n",
       "\n",
       "       lowest_kl highest_euclidean             lowest_euclidean  \\\n",
       "0     afd_mni_AC      fw_mni_F_L_R                rdt_mni_ICP_R   \n",
       "1  fw_mni_MdLF_R     afd_mni_ICP_L                 mdt_mni_AF_L   \n",
       "2   afd_mni_UF_R     fat_mni_F_L_R                mdt_mni_CCMid   \n",
       "3   fat_mni_AF_L      fw_mni_F_L_R                adt_mni_SLF_R   \n",
       "4    fat_mni_MCP    fat_mni_IFOF_R  mdt_mni_IIT_mask_skeletonFA   \n",
       "5   fa_mni_OPT_R     afd_mni_VOF_L                 ad_mni_CST_R   \n",
       "\n",
       "  highest_mahalanobis           lowest_mahalanobis  \n",
       "0           fw_mni_AC               afd_mni_MdLF_L  \n",
       "1         afd_mni_MCP                 fa_mni_OPT_R  \n",
       "2       fat_mni_CCMid                mdt_mni_ICP_R  \n",
       "3         fw_mni_UF_L                afd_mni_FPT_L  \n",
       "4       fa_mni_IFOF_R  mdt_mni_IIT_mask_skeletonFA  \n",
       "5      afd_mni_IFOF_L                 ad_mni_CST_R  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_path = 'RESULTS/DISTRIBUTION_RESULTS/distance_metrics_results.csv'\n",
    "distance_metrics_results = pd.read_csv(output_path)\n",
    "\n",
    "# Find the bundle/metric with the highest and lowest value for each distance metric for each disease\n",
    "highest_lowest_values = distance_metrics_results.groupby('disease').agg(\n",
    "    highest_bhattacharyya=('bhattacharyya_distance', lambda x: distance_metrics_results.loc[x.idxmax(), 'metric_bundle']),\n",
    "    lowest_bhattacharyya=('bhattacharyya_distance', lambda x: distance_metrics_results.loc[x.idxmin(), 'metric_bundle']),\n",
    "    highest_kl=('kl_divergence', lambda x: distance_metrics_results.loc[x.idxmax(), 'metric_bundle']),\n",
    "    lowest_kl=('kl_divergence', lambda x: distance_metrics_results.loc[x.idxmin(), 'metric_bundle']),\n",
    "    highest_euclidean=('euclidean_distance', lambda x: distance_metrics_results.loc[x.idxmax(), 'metric_bundle']),\n",
    "    lowest_euclidean=('euclidean_distance', lambda x: distance_metrics_results.loc[x.idxmin(), 'metric_bundle']),\n",
    "    highest_mahalanobis=('mahalanobis_distance', lambda x: distance_metrics_results.loc[x.idxmax(), 'metric_bundle']),\n",
    "    lowest_mahalanobis=('mahalanobis_distance', lambda x: distance_metrics_results.loc[x.idxmin(), 'metric_bundle'])\n",
    ").reset_index()\n",
    "\n",
    "highest_lowest_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # TEST ADD BIAIS\n",
    "# # Split the data into training and testing sets\n",
    "# directory = os.path.join(MAINFOLDER, \"testBiais\")\n",
    "# os.makedirs(directory, exist_ok=True)\n",
    "# train_df, test_df = split_train_test(CAMCAN, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Generate biased data\n",
    "# # Save the original non-biased data to temporary files\n",
    "# temp_train_file_original = os.path.join(directory, \"temp_train_original.csv\")\n",
    "# temp_test_file_original = os.path.join(directory, \"temp_test_original.csv\")\n",
    "# train_df.to_csv(temp_train_file_original, index=False)\n",
    "# test_df.to_csv(temp_test_file_original, index=False)\n",
    "\n",
    "# # Generate biased data\n",
    "# sampled_df_biaied, test_df_biaised, gammas,deltas, ruffles= generate_biaised_data(train_df, test_df)\n",
    "\n",
    "# # Save the biased data to temporary files\n",
    "# temp_train_file = os.path.join(directory, \"temp_train_biased.csv\")\n",
    "# temp_test_file = os.path.join(directory, \"temp_test_biased.csv\")\n",
    "# sampled_df_biaied.to_csv(temp_train_file, index=False)\n",
    "# test_df_biaised.to_csv(temp_test_file, index=False)\n",
    "\n",
    "# # Run the combat_visualize_data script\n",
    "# outname_train = os.path.join(\"visualize_train\")\n",
    "# cmd = (\n",
    "#     \"scripts/combat_visualize_data.py\"\n",
    "#     + \" \"\n",
    "#     + temp_train_file_original\n",
    "#     + \" \"\n",
    "#     + temp_train_file\n",
    "#     + \" --out_dir \"\n",
    "#     + directory\n",
    "#     + \" --outname \"\n",
    "#     + outname_train\n",
    "#     + \" -f\"\n",
    "#     + \" --bundles all\"\n",
    "# )\n",
    "# subprocess.call(cmd, shell=True)\n",
    "\n",
    "# # Display gammas and deltas along with their mean and standard deviation\n",
    "# print(\"Gammas:\", gammas)\n",
    "# print(\"Deltas:\", deltas)\n",
    "# gammas = list(gammas.values())\n",
    "# deltas = list(deltas.values())\n",
    "# print(\"\\nGamma Statistics:\")\n",
    "# print(f\"Mean: {np.mean(gammas)}, Std: {np.std(gammas)}\")\n",
    "\n",
    "# print(\"\\nDelta Statistics:\")\n",
    "# print(f\"Mean: {np.mean(deltas)}, Std: {np.std(deltas)}\")\n",
    "# print(\"Ruffles:\", ruffles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TEST Powerpoint generation\n",
    "# d  = os.path.join(MAINFOLDER, robust_method, \"adni_100_Philips_3T\")\n",
    "# create_presentation(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TEST the sample_patients function with compilation data data\n",
    "# sampled_df = sample_patients(COMPILATION, num_patients=100, disease_ratio=0.5)\n",
    "# print(sampled_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_metrics(\"ROBUST/IQR/50_30/0/\", \"50_patients_30_percent_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the dists_compilation and metrics_compilation CSV files\n",
    "# dists_compilation_path = os.path.join(directory, \"dists_compilation.csv\")\n",
    "# metrics_compilation_path = os.path.join(directory, \"metrics_compilation.csv\")\n",
    "\n",
    "# dists_compilation = pd.read_csv(dists_compilation_path)\n",
    "# metrics_compilation = pd.read_csv(metrics_compilation_path)\n",
    "\n",
    "# # Change the site column\n",
    "# dists_compilation['site'] = dists_compilation['site'].str.rsplit('_', n=1).str[0]\n",
    "# metrics_compilation['site'] = metrics_compilation['site'].str.rsplit('_', n=1).str[0]\n",
    "\n",
    "# # Display the means by site\n",
    "# dists_means_by_site = dists_compilation.groupby(['site','comparaison']).mean()\n",
    "# metrics_means_by_site = metrics_compilation.groupby('site').mean()\n",
    "\n",
    "# print(dists_means_by_site)\n",
    "# print(metrics_means_by_site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # FIX METRICS COMPILATION\n",
    "# directory = os.path.join(MAINFOLDER, robust_method)\n",
    "# df = pd.read_csv(os.path.join(directory, \"metrics_compilation.csv\"))\n",
    "\n",
    "# # Group by the site\n",
    "# grouped = df.groupby('site')\n",
    "\n",
    "# # Process each site\n",
    "# cleaned_dfs = []\n",
    "# for site, group in grouped:\n",
    "#     # Reset index for easier manipulation\n",
    "#     group = group.reset_index(drop=True)\n",
    "    \n",
    "#     # # The first row is the \"bundle row\" (new column names)\n",
    "#     # new_columns = group.iloc[0].values  # Extract column names from the first row\n",
    "#     # new_columns[-1] = 'site'\n",
    "#     # group = group.iloc[1:]  # Remove the first row\n",
    "    \n",
    "#     # # Assign new column names\n",
    "#     # group.columns = new_columns\n",
    "    \n",
    "#     # # Sort the columns alphabetically (excluding 'site')\n",
    "#     # sorted = group.sort_index(axis=1)\n",
    "#     # Add a new column 'nomm' with the value indicating the metric for each row\n",
    "#     metrics = ['tp', 'fp', 'tn', 'fn', 'precision', 'recall', 'taux_faux_positifs', 'f1_score']\n",
    "#     group['metric'] = metrics\n",
    "    \n",
    "#     # # Append the cleaned DataFrame for this site\n",
    "#     cleaned_dfs.append(group)\n",
    "\n",
    "# # Concatenate all cleaned DataFrames\n",
    "# final_df = pd.concat(cleaned_dfs, ignore_index=True)\n",
    "\n",
    "# # Save or display the result\n",
    "# final_df.to_csv(os.path.join(directory, \"metrics_compilation.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REAL SITES\n",
    "# directory = os.path.join(MAINFOLDER, robust_method)\n",
    "# raw_directory = os.path.join(RAWFOLDER, site_group)\n",
    "# for filename in sorted(os.listdir(raw_directory)):\n",
    "#     f = os.path.join(raw_directory, filename)\n",
    "#     # checking if it is a file\n",
    "#     if os.path.isfile(f):\n",
    "#         analyse_site(f, robust_method, directory)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD METRIC AND DIEASE COLUMNS\n",
    "# dists_compilation = pd.read_csv(os.path.join(MAINFOLDER, \"dists_compilation.csv\"))\n",
    "# mea_compilation = pd.read_csv(os.path.join(MAINFOLDER, \"mea_compilation.csv\"))\n",
    "# # List of metrics and diseases\n",
    "# metrics = ['ad', 'adt', 'afd', 'fa', 'fat', 'fw', 'md', 'mdt', 'rd', 'rdt']\n",
    "# diseases = [\"AD\", \"ADHD\", \"BIP\", \"MCI\", \"SCHZ\", \"TBI\"]\n",
    "# # Repeat each metric 2 times and then switch to the next metric\n",
    "# metrics_repeated = [metric for metric in metrics for _ in range(2)]\n",
    "\n",
    "# # Repeat the entire metrics list twice for each disease\n",
    "# metrics_final = metrics_repeated * 8 * len(diseases)\n",
    "\n",
    "# # Repeat each disease for the length of the metrics list repeated twice\n",
    "# diseases_final = [disease for disease in diseases for _ in range(len(metrics_repeated) * 8)]\n",
    "\n",
    "# # Add the new columns to the DataFrame\n",
    "# dists_compilation['metric'] = metrics_final[:len(dists_compilation)]\n",
    "# dists_compilation['disease'] = diseases_final[:len(dists_compilation)]\n",
    "\n",
    "# mea_compilation['metric'] = metrics_final[:len(mea_compilation)]\n",
    "# mea_compilation['disease'] = diseases_final[:len(mea_compilation)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".robust",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
