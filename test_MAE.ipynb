{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTS and UTILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print(\"hi\")\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import re\n",
    "import numpy as np\n",
    "import json\n",
    "import csv\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "from scripts import combat_info\n",
    "from scripts import combat_quick_apply\n",
    "from scripts import combat_quick_QC\n",
    "from robust_evaluation_tools.robust_utils import get_site, robust_text, rwp_text, get_camcan_file, get_diseases, get_metrics, add_nb_patients_and_diseased\n",
    "from robust_evaluation_tools.robust_harmonization import fit, apply, visualize_harmonization, QC, compare_with_compilation, create_presentation, compare_distances, compare_with_compilation_var\n",
    "from robust_evaluation_tools.synthectic_sites_generations import generate_sites\n",
    "\n",
    "MAINFOLDER = \"RESULTS/MAE_TEST\"\n",
    "SYNTHETIC_SITES = f\"{MAINFOLDER}/SYNTHETIC_SITES\"\n",
    "\n",
    "ANALYSIS_FOLDER = f\"{MAINFOLDER}/ANALYSIS\"\n",
    "\n",
    "robust_methods_for_analysis = [\"MMS\",\"IQR\",'MAD', 'VS', 'VS2', 'TOP30']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HARMONIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def harmonize(f_train, ref_data_file, metric,harmonizartion_method, f_test, directory, robust, rwp,hc):\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    print(f_train)\n",
    "    \n",
    "    # Fit the model\n",
    "    output_model_filename = fit(f_train, ref_data_file, metric, harmonizartion_method, robust, rwp, directory, hc,)\n",
    "    # Apply the model\n",
    "    output_filename = apply(f_test, output_model_filename, metric, harmonizartion_method, robust, rwp, directory)\n",
    "    \n",
    "    # Visualize the harmonization\n",
    "    #visualize_harmonization(f_test, output_filename, ref_data_file, directory, bundles = '')\n",
    "    mae = compare_with_compilation(pd.read_csv(output_filename))\n",
    "    maev = compare_with_compilation_var(pd.read_csv(output_filename))\n",
    "\n",
    "    mae['site'] = get_site(f_train)\n",
    "    maev['site'] = get_site(f_train)\n",
    "    \n",
    "    return mae, maev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_site(f_train,f_test, robust, directory, ref_data_file, metric,harmonizartion_method):\n",
    "    # 4 harmonization\n",
    "    harmonization_hc, maev_hc = harmonize(f_train, ref_data_file, metric,harmonizartion_method, f_test, os.path.join(directory, \"hc\"), \"No\", False, True)\n",
    "    harmonization_no_robust, maev_no_robust = harmonize(f_train, ref_data_file, metric,harmonizartion_method, f_test, os.path.join(directory, \"NoRobust\"), \"No\", False, False)\n",
    "    harmonization_robust, maev_robust = harmonize(f_train, ref_data_file, metric,harmonizartion_method, f_test, os.path.join(directory, \"robust\"), robust, False, False)\n",
    "    harmonization_robust_rwp, maev_robust_rwp = harmonize(f_train, ref_data_file, metric,harmonizartion_method, f_test, os.path.join(directory, \"robust_rwp\"), robust, True, False)\n",
    "\n",
    "\n",
    "    #create_presentation(directory, harmonizartion_method)\n",
    "\n",
    "    # Combine MEA in a single DataFrame\n",
    "    mea_combined = pd.concat([harmonization_hc, harmonization_no_robust, harmonization_robust, harmonization_robust_rwp], ignore_index=True)\n",
    "    mea_combined['method'] = ['hc', 'no_robust', 'robust', 'robust_rwp']\n",
    "\n",
    "    maev_combined = pd.concat([maev_hc, maev_no_robust, maev_robust, maev_robust_rwp], ignore_index=True)\n",
    "    maev_combined['method'] = ['hc', 'no_robust', 'robust', 'robust_rwp']\n",
    "\n",
    "\n",
    "    #TODO bundles et analyze outliers\n",
    "    return mea_combined, maev_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "# #Analyse Method\n",
    "# def analyse_method(sample_sizes, disease_ratios, num_tests, robust_method, SYNTHETIC_SITES_VERSION):\n",
    "#     # Split the data into training and testing sets\n",
    "#     directory = os.path.join(MAINFOLDER, robust_method)\n",
    "#     directory_site = os.path.join(SYNTHETIC_SITES ,SYNTHETIC_SITES_VERSION)\n",
    "#     # Initialize DataFrames to store the results\n",
    "#     detection_measures_compilation = pd.DataFrame()\n",
    "#     dists_compilation = pd.DataFrame()\n",
    "#     mea_compilation = pd.DataFrame()\n",
    "#     outliers_compilation = pd.DataFrame()\n",
    "#     for sample_size in sample_sizes:\n",
    "#         for disease_ratio in disease_ratios:        \n",
    "#             sizeDir = os.path.join(directory, f\"{sample_size}_{int(disease_ratio*100)}\")\n",
    "#             sizeDir_site = os.path.join(directory_site, f\"{sample_size}_{int(disease_ratio*100)}\")\n",
    "#             for i in range(num_tests):\n",
    "#                 tempDir = os.path.join(sizeDir, f\"{i}\")\n",
    "#                 tempDir_site = os.path.join(sizeDir_site, f\"{i}\")\n",
    "#                 os.makedirs(tempDir, exist_ok=True)\n",
    "\n",
    "#                 train_file_name = f\"train_{sample_size}_{int(disease_ratio*100)}_{i}.csv\"\n",
    "#                 test_file_name = f\"test_{sample_size}_{int(disease_ratio*100)}_{i}.csv\"\n",
    "                \n",
    "#                 # Sauvegarder l'échantillon dans un fichier temporaire\n",
    "#                 train_file = os.path.join(tempDir_site,train_file_name )\n",
    "#                 train_df = pd.read_csv(train_file)\n",
    "#                 train_df.to_csv(os.path.join(tempDir,train_file_name ), index=False)\n",
    "\n",
    "#                 test_file = os.path.join(tempDir_site, test_file_name)\n",
    "#                 test_df = pd.read_csv(test_file)\n",
    "#                 test_df.to_csv(os.path.join(tempDir,test_file_name ), index=False)\n",
    "\n",
    "#                 ref_data_file = get_camcan_file(metric='fd')\n",
    "                \n",
    "#                 # Analyser le site pour le nouvel échantillon\n",
    "#                 dists_analyze, mea_analyze, detection_measures, outliers = analyse_site(train_file, test_file, robust_method, tempDir, ref_data_file, metric,harmonizartion_method)\n",
    "#                 analyse_site(f_train,f_test, robust, directory, ref_data_file, metric,harmonizartion_method)\n",
    "#                 detection_measures_compilation = pd.concat([detection_measures_compilation, detection_measures])\n",
    "#                 dists_compilation = pd.concat([dists_compilation, dists_analyze])\n",
    "#                 mea_compilation = pd.concat([mea_compilation, mea_analyze])\n",
    "#                 outliers_compilation = pd.concat([outliers_compilation, outliers])\n",
    "#     # Save the metrics and distances compilation DataFrames to CSV files\n",
    "#     detection_measures_compilation.to_csv(os.path.join(directory, \"detection_measures__compilation.csv\"), index=False)\n",
    "#     dists_compilation.to_csv(os.path.join(directory, \"dists_compilation.csv\"), index=False)\n",
    "#     mea_compilation.to_csv(os.path.join(directory, \"mea_compilation.csv\"), index=False)\n",
    "#     outliers_compilation.to_csv(os.path.join(directory, \"outliers_compilation.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to analyze a single (sample_size, disease_ratio) combination\n",
    "def process_analysis(disease, metric, sample_size, disease_ratio,harmonization_method, robust_method, SYNTHETIC_SITES_VERSION, num_tests):\n",
    "    directory = os.path.join(MAINFOLDER, robust_method, disease, metric)\n",
    "    directory_site = os.path.join(SYNTHETIC_SITES, SYNTHETIC_SITES_VERSION,disease)\n",
    "    \n",
    "    sizeDir = os.path.join(directory, f\"{sample_size}_{int(disease_ratio * 100)}\")\n",
    "    sizeDir_site = os.path.join(directory_site, f\"{sample_size}_{int(disease_ratio * 100)}\")\n",
    "\n",
    "    mea_compilation = pd.DataFrame()\n",
    "    maev_compilation = pd.DataFrame()\n",
    "\n",
    "    for test_index in range(num_tests):\n",
    "        tempDir = os.path.join(sizeDir, f\"{test_index}\")\n",
    "        tempDir_site = os.path.join(sizeDir_site, f\"{test_index}\")\n",
    "        os.makedirs(tempDir, exist_ok=True)\n",
    "\n",
    "        train_file_name = f\"train_{sample_size}_{int(disease_ratio * 100)}_{test_index}_{metric}.csv\"\n",
    "        test_file_name = f\"test_{sample_size}_{int(disease_ratio * 100)}_{test_index}_{metric}.csv\"\n",
    "\n",
    "        # Load and save training dataset\n",
    "        train_file = os.path.join(tempDir_site, train_file_name)\n",
    "        train_df = pd.read_csv(train_file)\n",
    "        train_df = train_df[~train_df['bundle'].isin(['left_ventricle', 'right_ventricle'])]\n",
    "        train_df = train_df.drop(columns=['mean_no_cov', 'metric_bundle'])\n",
    "        new_train_file = os.path.join(tempDir, train_file_name)\n",
    "        train_df.to_csv(new_train_file, index=False)\n",
    "        \n",
    "\n",
    "        # Load and save test dataset\n",
    "        test_file = os.path.join(tempDir_site, test_file_name)\n",
    "        test_df = pd.read_csv(test_file)\n",
    "        test_df = test_df[~test_df['bundle'].isin(['left_ventricle', 'right_ventricle'])]\n",
    "        test_df = test_df.drop(columns=['mean_no_cov', 'metric_bundle'])\n",
    "        new_test_file = os.path.join(tempDir, test_file_name)\n",
    "        test_df.to_csv(new_test_file, index=False)\n",
    "\n",
    "        ref_data_file = get_camcan_file(metric)\n",
    "\n",
    "        # Analyze the site\n",
    "        mea_analyze, maev_analyze = analyse_site(\n",
    "            new_train_file, new_test_file, robust_method, tempDir, ref_data_file, metric, harmonization_method\n",
    "        )\n",
    "        mea_analyze['robust_method'] = robust_method\n",
    "        mea_analyze['disease'] = disease\n",
    "        mea_analyze['metric'] = metric\n",
    "\n",
    "        maev_analyze['robust_method'] = robust_method\n",
    "        maev_analyze['disease'] = disease\n",
    "        maev_analyze['metric'] = metric\n",
    "\n",
    "        mea_compilation = pd.concat([mea_compilation, mea_analyze], ignore_index=True)\n",
    "        maev_compilation = pd.concat([maev_compilation, maev_analyze], ignore_index=True)\n",
    "        \n",
    "\n",
    "    # Sauvegarde les deux compilations\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    mea_file_path = os.path.join(sizeDir, \"mea_compilation.csv\")\n",
    "    maev_file_path = os.path.join(sizeDir, \"maev_compilation.csv\")\n",
    "\n",
    "    mea_compilation.to_csv(mea_file_path, index=False)\n",
    "    maev_compilation.to_csv(maev_file_path, index=False)\n",
    "\n",
    "    # On retourne les deux chemins de fichiers\n",
    "    return (mea_file_path, maev_file_path)\n",
    "\n",
    "# Parallelized analysis method (excluding num_tests from parallelization)\n",
    "def analyse_method(sample_sizes, disease_ratios, num_tests, robust_methods,diseases, metrics, harmonization_method, SYNTHETIC_SITES_VERSION):\n",
    "    # Generate all task combinations (excluding num_tests)\n",
    "    tasks = [\n",
    "        (disease,metric, sample_size, disease_ratio,harmonization_method, robust_method, SYNTHETIC_SITES_VERSION, num_tests)\n",
    "        for robust_method in robust_methods\n",
    "        for disease in diseases\n",
    "        for sample_size in sample_sizes\n",
    "        for disease_ratio in disease_ratios\n",
    "        for metric in metrics\n",
    "    ]\n",
    "\n",
    "    # Run all combinations in parallel and collect file paths\n",
    "    results = Parallel(n_jobs=-1)(delayed(process_analysis)(*task) for task in tasks)\n",
    "\n",
    "     # On sépare la liste de tuples en deux listes de chemins\n",
    "    mea_file_paths = [res[0] for res in results]\n",
    "    maev_file_paths = [res[1] for res in results]\n",
    "\n",
    "    # Concatène toutes les compilations mea\n",
    "    mea_compilation_global = pd.concat(\n",
    "        [pd.read_csv(fpath) for fpath in mea_file_paths],\n",
    "        ignore_index=True\n",
    "    )\n",
    "\n",
    "    # Concatène toutes les compilations maev\n",
    "    maev_compilation_global = pd.concat(\n",
    "        [pd.read_csv(fpath) for fpath in maev_file_paths],\n",
    "        ignore_index=True\n",
    "    )\n",
    "\n",
    "    # Sauvegarde finale des deux DataFrames compilés\n",
    "    directory = os.path.join(MAINFOLDER)\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "    mea_compilation_global.to_csv(os.path.join(directory, \"mea_compilation_global.csv\"), index=False)\n",
    "    maev_compilation_global.to_csv(os.path.join(directory, \"maev_compilation_global.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sites_for_disease(disease, SYNTHETIC_SITES, SYNTHETIC_SITES_VERSION, sample_sizes, disease_ratios, num_tests):\n",
    "    # Load data for the disease\n",
    "    data_path = path = os.path.join('DONNES','COMPILATIONS_AUG_3', f'{disease}_combination_all_metrics_CamCAN.csv.gz')\n",
    "\n",
    "    # Define site directory\n",
    "    directory_site = os.path.join(SYNTHETIC_SITES, SYNTHETIC_SITES_VERSION, disease)\n",
    "\n",
    "    # Generate synthetic sites\n",
    "    generate_sites(sample_sizes, disease_ratios, num_tests, directory_site, data_path, disease=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXECUTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "harmonization_method= \"classic\"\n",
    "\n",
    "SYNTHETIC_SITES_VERSION = \"v1\"\n",
    "\n",
    "metrics = get_metrics()\n",
    "#diseases = get_diseases(True)\n",
    "diseases = [\"AD\",\"SYN_2\"]\n",
    "robust_methods = [\"MMS\",\"IQR\",'MAD', 'VS', 'VS2', 'TOP30', 'TOP50']\n",
    "\n",
    "\n",
    "sample_sizes = [100]  # Différentes tailles d'échantillon\n",
    "disease_ratios = [0.1, 0.3, 0.5]  # Différents pourcentages de malades\n",
    "num_tests = 6  # Nombre de tests à effectuer pour chaque combinaison\n",
    "\n",
    "# Parallel(n_jobs=-1)(\n",
    "#     delayed(generate_sites_for_disease)(disease, SYNTHETIC_SITES, SYNTHETIC_SITES_VERSION, sample_sizes, disease_ratios, num_tests)\n",
    "#     for disease in diseases\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyse_method(sample_sizes, disease_ratios, num_tests, robust_methods,diseases, metrics, harmonization_method, SYNTHETIC_SITES_VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le fichier principal\n",
    "mea_compilation = pd.read_csv(os.path.join(MAINFOLDER, \"mea_compilation_global.csv\"))\n",
    "\n",
    "# Récupérer les méthodes uniques\n",
    "methods = mea_compilation['robust_method'].unique()\n",
    "\n",
    "# Sauvegarder un fichier CSV pour chaque méthode\n",
    "for method in methods:\n",
    "    # Filtrer les lignes correspondant à la méthode\n",
    "    method_df = mea_compilation[mea_compilation['robust_method'] == method]\n",
    "    \n",
    "    # Créer un dossier pour la méthode\n",
    "    method_directory = os.path.join(MAINFOLDER, method)\n",
    "    os.makedirs(method_directory, exist_ok=True)\n",
    "    \n",
    "    # Sauvegarder le fichier CSV dans le dossier\n",
    "    method_file_path = os.path.join(method_directory, f\"{method}_mea_compilation.csv\")\n",
    "    method_df.to_csv(method_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le fichier principal\n",
    "maev_compilation = pd.read_csv(os.path.join(MAINFOLDER, \"maev_compilation_global.csv\"))\n",
    "\n",
    "# Récupérer les méthodes uniques\n",
    "methods = maev_compilation['robust_method'].unique()\n",
    "\n",
    "# Sauvegarder un fichier CSV pour chaque méthode\n",
    "for method in methods:\n",
    "    # Filtrer les lignes correspondant à la méthode\n",
    "    method_df = maev_compilation[maev_compilation['robust_method'] == method]\n",
    "    \n",
    "    # Créer un dossier pour la méthode\n",
    "    method_directory = os.path.join(MAINFOLDER, method)\n",
    "    os.makedirs(method_directory, exist_ok=True)\n",
    "    \n",
    "    # Sauvegarder le fichier CSV dans le dossier\n",
    "    method_file_path = os.path.join(method_directory, f\"{method}_maev_compilation.csv\")\n",
    "    method_df.to_csv(method_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_all_method_files(main_folder, methods):\n",
    "    all_dfs = []\n",
    "    for m in methods:\n",
    "        path = os.path.join(main_folder, m, f\"{m}_mea_compilation.csv\")\n",
    "        if os.path.exists(path):\n",
    "            df = pd.read_csv(path)\n",
    "            all_dfs.append(df)\n",
    "    return pd.concat(all_dfs, ignore_index=True) if all_dfs else pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_all_method_files_maev(main_folder, methods):\n",
    "    all_dfs = []\n",
    "    for m in methods:\n",
    "        path = os.path.join(main_folder, m, f\"{m}_maev_compilation.csv\")\n",
    "        if os.path.exists(path):\n",
    "            df = pd.read_csv(path)\n",
    "            all_dfs.append(df)\n",
    "    return pd.concat(all_dfs, ignore_index=True) if all_dfs else pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def plot_mea(df, sample_size, disease, metric, directory):\n",
    "    directory = os.path.join(directory, \"MAE_PLOTS\", disease, metric, str(sample_size))\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    \n",
    "    df_filtered = df[\n",
    "        (df['num_patients'] == sample_size) & \n",
    "        (df['disease'] == disease) & \n",
    "        (df['metric'] == metric)\n",
    "    ]\n",
    "\n",
    "    # Méthodes de base + méthodes robustes\n",
    "    robust_methods = df_filtered['robust_method'].dropna().unique()\n",
    "    base_methods = [\"hc\", \"no_robust\"]\n",
    "    robust_base_methods = [\"robust\"]\n",
    "    methods = base_methods + [f\"{rb}_{rm}\" for rb in robust_base_methods for rm in robust_methods]\n",
    "    \n",
    "    # Couleurs\n",
    "    method_colors = {\n",
    "        \"hc\": \"green\",\n",
    "        \"no_robust\": \"red\"\n",
    "    }\n",
    "    robust_palette = sns.color_palette(\"viridis\", len(robust_methods))\n",
    "    robust_rwp_palette = sns.color_palette(\"magma\", len(robust_methods))\n",
    "    for i, rm in enumerate(robust_methods):\n",
    "        method_colors[f\"robust_{rm}\"] = robust_palette[i]\n",
    "        method_colors[f\"robust_rwp_{rm}\"] = robust_rwp_palette[i]\n",
    "\n",
    "    # Boucle sur les \"bundles\"\n",
    "    for bundle_column in df_filtered.columns:\n",
    "        # On ignore les colonnes non-numériques\n",
    "        if bundle_column in ['site', 'method', 'num_patients', 'disease_ratio',\n",
    "                             'num_diseased', 'metric', 'disease', 'robust_method']:\n",
    "            continue\n",
    "\n",
    "        bundle_df = df_filtered[[bundle_column, 'site', 'method', 'num_patients',\n",
    "                                 'disease_ratio', 'num_diseased', 'robust_method']].copy()\n",
    "        unique_ratios = sorted(bundle_df['disease_ratio'].unique())  # Trié pour être sûr de l'ordre\n",
    "\n",
    "        # *** ICI on paramètre la figure + le positionnement ***\n",
    "        fig, ax = plt.subplots(figsize=(14, 7))  # Ajuster au besoin\n",
    "\n",
    "        # Abscisses pour chaque ratio\n",
    "        x = np.arange(len(unique_ratios))\n",
    "        \n",
    "        # Largeur totale allouée pour le « groupe » de méthodes à chaque ratio\n",
    "        group_width = 0.8  \n",
    "        # On répartit cette largeur entre toutes les méthodes\n",
    "        n_methods = len(methods)\n",
    "        box_width = group_width / n_methods\n",
    "\n",
    "        # Tracé des boxplots pour chaque méthode\n",
    "        for i_m, method in enumerate(methods):\n",
    "            if \"_\" in method and method != \"no_robust\":\n",
    "                method_base, robust_type = method.rsplit(\"_\", 1)\n",
    "                method_df = bundle_df[\n",
    "                    (bundle_df['method'] == method_base) & \n",
    "                    (bundle_df['robust_method'] == robust_type)\n",
    "                ]\n",
    "            else:\n",
    "                method_df = bundle_df[bundle_df['method'] == method]\n",
    "\n",
    "            # On prépare la liste de valeurs par ratio\n",
    "            data = [\n",
    "                method_df[method_df['disease_ratio'] == ratio][bundle_column].values \n",
    "                for ratio in unique_ratios\n",
    "            ]\n",
    "\n",
    "            # Positions: on centre autour de chaque x\n",
    "            # Exemple: x - group_width/2 + (i_m+0.5)*box_width\n",
    "            positions = x - group_width/2 + (i_m + 0.5)*box_width\n",
    "\n",
    "            color = method_colors.get(method, \"black\")\n",
    "            \n",
    "            # S’il y a au moins un point de données\n",
    "            if any(len(d) > 0 for d in data):\n",
    "                ax.boxplot(\n",
    "                    data,\n",
    "                    positions=positions,\n",
    "                    widths=box_width * 0.8,  # Légèrement plus petit que box_width\n",
    "                    patch_artist=True,\n",
    "                    boxprops=dict(facecolor=color, color=color),\n",
    "                    medianprops=dict(color='black')\n",
    "                )\n",
    "\n",
    "        ax.set_xlabel('Prct de patients malades')\n",
    "        ax.set_ylabel('MAE')\n",
    "        ax.set_title(\n",
    "            f\"MAE de l'harmonization selon le pourcentage de patients malades\\n\"\n",
    "            f\"Maladie: {disease}  |  Metric: {metric}  |  Bundle: {bundle_column}\\n\"\n",
    "            f\"Nb patient total: {sample_size}\"\n",
    "        )\n",
    "\n",
    "        # On place les ticks au milieu de chaque groupe (i.e. sur x)\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(unique_ratios)\n",
    "\n",
    "        # Légende manuelle\n",
    "        legend_handles = [\n",
    "            plt.Line2D([0], [0], color=method_colors[m], lw=3, label=f'Method: {m}')\n",
    "            for m in methods\n",
    "        ]\n",
    "        ax.legend(handles=legend_handles, loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(directory, f'{bundle_column}_boxplot.png'), bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "mea_df = gather_all_method_files(MAINFOLDER, robust_methods_for_analysis)\n",
    "add_nb_patients_and_diseased(mea_df)\n",
    "\n",
    "# Generate all task combinations\n",
    "tasks = [\n",
    "    (mea_df, sample_size, disease, metric, ANALYSIS_FOLDER)\n",
    "    for disease in diseases\n",
    "    for sample_size in sample_sizes\n",
    "    for metric in metrics\n",
    "]\n",
    "\n",
    "# Run all tasks in parallel\n",
    "Parallel(n_jobs=-1)(\n",
    "    delayed(plot_mea)(*task) for task in tasks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def plot_maev(df, sample_size, disease, metric, directory):\n",
    "    directory = os.path.join(directory, \"MAEV_PLOTS\", disease, metric, str(sample_size))\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    \n",
    "    df_filtered = df[\n",
    "        (df['num_patients'] == sample_size) & \n",
    "        (df['disease'] == disease) & \n",
    "        (df['metric'] == metric)\n",
    "    ]\n",
    "\n",
    "    # Méthodes de base + méthodes robustes\n",
    "    robust_methods = df_filtered['robust_method'].dropna().unique()\n",
    "    base_methods = [\"hc\", \"no_robust\"]\n",
    "    robust_base_methods = [\"robust\",]\n",
    "    methods = base_methods + [f\"{rb}_{rm}\" for rb in robust_base_methods for rm in robust_methods]\n",
    "    \n",
    "    # Couleurs\n",
    "    method_colors = {\n",
    "        \"hc\": \"green\",\n",
    "        \"no_robust\": \"red\"\n",
    "    }\n",
    "    robust_palette = sns.color_palette(\"viridis\", len(robust_methods))\n",
    "    robust_rwp_palette = sns.color_palette(\"magma\", len(robust_methods))\n",
    "    for i, rm in enumerate(robust_methods):\n",
    "        method_colors[f\"robust_{rm}\"] = robust_palette[i]\n",
    "        method_colors[f\"robust_rwp_{rm}\"] = robust_rwp_palette[i]\n",
    "\n",
    "    # Boucle sur les \"bundles\"\n",
    "    for bundle_column in df_filtered.columns:\n",
    "        # On ignore les colonnes non-numériques\n",
    "        if bundle_column in ['site', 'method', 'num_patients', 'disease_ratio',\n",
    "                             'num_diseased', 'metric', 'disease', 'robust_method']:\n",
    "            continue\n",
    "\n",
    "        bundle_df = df_filtered[[bundle_column, 'site', 'method', 'num_patients',\n",
    "                                 'disease_ratio', 'num_diseased', 'robust_method']].copy()\n",
    "        unique_ratios = sorted(bundle_df['disease_ratio'].unique())  # Trié pour être sûr de l'ordre\n",
    "\n",
    "        # *** ICI on paramètre la figure + le positionnement ***\n",
    "        fig, ax = plt.subplots(figsize=(14, 7))  # Ajuster au besoin\n",
    "\n",
    "        # Abscisses pour chaque ratio\n",
    "        x = np.arange(len(unique_ratios))\n",
    "        \n",
    "        # Largeur totale allouée pour le « groupe » de méthodes à chaque ratio\n",
    "        group_width = 0.8  \n",
    "        # On répartit cette largeur entre toutes les méthodes\n",
    "        n_methods = len(methods)\n",
    "        box_width = group_width / n_methods\n",
    "\n",
    "        # Tracé des boxplots pour chaque méthode\n",
    "        for i_m, method in enumerate(methods):\n",
    "            if \"_\" in method and method != \"no_robust\":\n",
    "                method_base, robust_type = method.rsplit(\"_\", 1)\n",
    "                method_df = bundle_df[\n",
    "                    (bundle_df['method'] == method_base) & \n",
    "                    (bundle_df['robust_method'] == robust_type)\n",
    "                ]\n",
    "            else:\n",
    "                method_df = bundle_df[bundle_df['method'] == method]\n",
    "\n",
    "            # On prépare la liste de valeurs par ratio\n",
    "            data = [\n",
    "                method_df[method_df['disease_ratio'] == ratio][bundle_column].values \n",
    "                for ratio in unique_ratios\n",
    "            ]\n",
    "\n",
    "            # Positions: on centre autour de chaque x\n",
    "            # Exemple: x - group_width/2 + (i_m+0.5)*box_width\n",
    "            positions = x - group_width/2 + (i_m + 0.5)*box_width\n",
    "\n",
    "            color = method_colors.get(method, \"black\")\n",
    "            \n",
    "            # S’il y a au moins un point de données\n",
    "            if any(len(d) > 0 for d in data):\n",
    "                ax.boxplot(\n",
    "                    data,\n",
    "                    positions=positions,\n",
    "                    widths=box_width * 0.8,  # Légèrement plus petit que box_width\n",
    "                    patch_artist=True,\n",
    "                    boxprops=dict(facecolor=color, color=color),\n",
    "                    medianprops=dict(color='black')\n",
    "                )\n",
    "\n",
    "        ax.set_xlabel('Prct de patients malades')\n",
    "        ax.set_ylabel('MAEV')\n",
    "        ax.set_title(\n",
    "            f\"MAEV de l'harmonization selon le pourcentage de patients malades\\n\"\n",
    "            f\"Maladie: {disease}  |  Metric: {metric}  |  Bundle: {bundle_column}\\n\"\n",
    "            f\"Nb patient total: {sample_size}\"\n",
    "        )\n",
    "\n",
    "        # On place les ticks au milieu de chaque groupe (i.e. sur x)\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(unique_ratios)\n",
    "\n",
    "        # Légende manuelle\n",
    "        legend_handles = [\n",
    "            plt.Line2D([0], [0], color=method_colors[m], lw=3, label=f'Method: {m}')\n",
    "            for m in methods\n",
    "        ]\n",
    "        ax.legend(handles=legend_handles, loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(directory, f'{bundle_column}_boxplot.png'), bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "mea_df = gather_all_method_files_maev(MAINFOLDER, robust_methods_for_analysis)\n",
    "add_nb_patients_and_diseased(mea_df)\n",
    "\n",
    "# Generate all task combinations\n",
    "tasks = [\n",
    "    (mea_df, sample_size, disease, metric, ANALYSIS_FOLDER)\n",
    "    for disease in diseases\n",
    "    for sample_size in sample_sizes\n",
    "    for metric in metrics\n",
    "]\n",
    "\n",
    "# Run all tasks in parallel\n",
    "Parallel(n_jobs=-1)(\n",
    "    delayed(plot_maev)(*task) for task in tasks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CREATION BOX PLOT POUR MEA\n",
    "# def plot_bundle(df, prct, directory):\n",
    "#     \"\"\"\n",
    "#     Crée un graphique pour chaque bundle dans le DataFrame donné.\n",
    "#     L'axe des X représente le nombre de patients et l'axe des Y représente la moyenne de la colonne du bundle.\n",
    "#     La courbe inclut une zone indiquant l'écart-type (std).\n",
    "\n",
    "#     Parameters:\n",
    "#     df (pd.DataFrame): Le DataFrame contenant les données.\n",
    "#     bundle_column (str): Le nom de la colonne du bundle à utiliser pour le graphique.\n",
    "#     \"\"\"\n",
    "#     directory = os.path.join(directory, \"MEA_PLOTS\", str(prct))\n",
    "#     df = df[df['disease_ratio'] == prct *100]\n",
    "#     os.makedirs(directory, exist_ok=True)\n",
    "    \n",
    "#     for bundle_column in df.columns:\n",
    "#         if bundle_column in ['site','method','num_patients','disease_ratio','num_diseased']:\n",
    "#             continue # Skip non-numeric columns\n",
    "#         bundle_df = df[[bundle_column, 'site', 'method','num_patients','disease_ratio','num_diseased']].copy()\n",
    "#         methods = [\"hc\", \"no_robust\", \"robust\", \"robust_rwp\"]\n",
    "#         colors = ['blue', 'green', 'red', 'purple']\n",
    "        \n",
    "#         plt.figure(figsize=(10, 5))\n",
    "#         width = 0.2  # the width of the bars\n",
    "#         x = np.arange(len(bundle_df['num_patients'].unique()))  # the label locations\n",
    "#         fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "#         for i, (method, color) in enumerate(zip(methods, colors)):\n",
    "#             method_df = bundle_df[bundle_df['method'] == method]\n",
    "#             data = [method_df[method_df['num_patients'] == patients][bundle_column].values \n",
    "#                     for patients in bundle_df['num_patients'].unique()]\n",
    "            \n",
    "#             # Ensure there is data for each num_patients\n",
    "#             if any(len(d) > 0 for d in data):\n",
    "#                 positions = x + i * width  # Shift positions for each method\n",
    "#                 ax.boxplot(data, positions=positions, widths=0.15, patch_artist=True, \n",
    "#                         boxprops=dict(facecolor=color, color=color),\n",
    "#                         medianprops=dict(color='black'))\n",
    "                \n",
    "#         ax.set_xlabel('Nombre de patients')\n",
    "#         ax.set_ylabel('Valeurs')\n",
    "#         ax.set_title(f'Boxplots pour le bundle: {bundle_column} avec {prct * 100}% de malades')\n",
    "#         ax.set_xticks(x + width * (len(methods) - 1) / 2)\n",
    "#         ax.set_xticklabels(bundle_df['num_patients'].unique())\n",
    "#         ax.legend(handles=[plt.Line2D([0], [0], color=color, lw=4, label=f'Method: {method}') for method, color in zip(methods, colors)])\n",
    "#         plt.savefig(os.path.join(directory, f'{bundle_column}_boxplot.png'))\n",
    "#         plt.close()\n",
    "\n",
    "# # Exemple d'utilisation\n",
    "# mea_df = pd.read_csv(os.path.join(MAINFOLDER, robust_method, \"mea_compilation.csv\"))\n",
    "# add_nb_patients_and_diseased(mea_df)\n",
    "# disease_ratios = [0.1, 0.3, 0.5, 0.7]\n",
    "# for disease_ratio in disease_ratios:\n",
    "#     plot_bundle(mea_df, disease_ratio, os.path.join(MAINFOLDER, robust_method, ANALYSISFOLDER))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # TEST ADD BIAIS\n",
    "# # Split the data into training and testing sets\n",
    "# directory = os.path.join(MAINFOLDER, \"testBiais\")\n",
    "# os.makedirs(directory, exist_ok=True)\n",
    "# train_df, test_df = split_train_test(CAMCAN, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Generate biased data\n",
    "# # Save the original non-biased data to temporary files\n",
    "# temp_train_file_original = os.path.join(directory, \"temp_train_original.csv\")\n",
    "# temp_test_file_original = os.path.join(directory, \"temp_test_original.csv\")\n",
    "# train_df.to_csv(temp_train_file_original, index=False)\n",
    "# test_df.to_csv(temp_test_file_original, index=False)\n",
    "\n",
    "# # Generate biased data\n",
    "# sampled_df_biaied, test_df_biaised, gammas,deltas, ruffles= generate_biaised_data(train_df, test_df)\n",
    "\n",
    "# # Save the biased data to temporary files\n",
    "# temp_train_file = os.path.join(directory, \"temp_train_biased.csv\")\n",
    "# temp_test_file = os.path.join(directory, \"temp_test_biased.csv\")\n",
    "# sampled_df_biaied.to_csv(temp_train_file, index=False)\n",
    "# test_df_biaised.to_csv(temp_test_file, index=False)\n",
    "\n",
    "# # Run the combat_visualize_data script\n",
    "# outname_train = os.path.join(\"visualize_train\")\n",
    "# cmd = (\n",
    "#     \"scripts/combat_visualize_data.py\"\n",
    "#     + \" \"\n",
    "#     + temp_train_file_original\n",
    "#     + \" \"\n",
    "#     + temp_train_file\n",
    "#     + \" --out_dir \"\n",
    "#     + directory\n",
    "#     + \" --outname \"\n",
    "#     + outname_train\n",
    "#     + \" -f\"\n",
    "#     + \" --bundles all\"\n",
    "# )\n",
    "# subprocess.call(cmd, shell=True)\n",
    "\n",
    "# # Display gammas and deltas along with their mean and standard deviation\n",
    "# print(\"Gammas:\", gammas)\n",
    "# print(\"Deltas:\", deltas)\n",
    "# gammas = list(gammas.values())\n",
    "# deltas = list(deltas.values())\n",
    "# print(\"\\nGamma Statistics:\")\n",
    "# print(f\"Mean: {np.mean(gammas)}, Std: {np.std(gammas)}\")\n",
    "\n",
    "# print(\"\\nDelta Statistics:\")\n",
    "# print(f\"Mean: {np.mean(deltas)}, Std: {np.std(deltas)}\")\n",
    "# print(\"Ruffles:\", ruffles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TEST Powerpoint generation\n",
    "# d  = os.path.join(MAINFOLDER, robust_method, \"adni_100_Philips_3T\")\n",
    "# create_presentation(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TEST the sample_patients function with compilation data data\n",
    "# sampled_df = sample_patients(COMPILATION, num_patients=100, disease_ratio=0.5)\n",
    "# print(sampled_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_metrics(\"ROBUST/IQR/50_30/0/\", \"50_patients_30_percent_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the dists_compilation and metrics_compilation CSV files\n",
    "# dists_compilation_path = os.path.join(directory, \"dists_compilation.csv\")\n",
    "# metrics_compilation_path = os.path.join(directory, \"metrics_compilation.csv\")\n",
    "\n",
    "# dists_compilation = pd.read_csv(dists_compilation_path)\n",
    "# metrics_compilation = pd.read_csv(metrics_compilation_path)\n",
    "\n",
    "# # Change the site column\n",
    "# dists_compilation['site'] = dists_compilation['site'].str.rsplit('_', n=1).str[0]\n",
    "# metrics_compilation['site'] = metrics_compilation['site'].str.rsplit('_', n=1).str[0]\n",
    "\n",
    "# # Display the means by site\n",
    "# dists_means_by_site = dists_compilation.groupby(['site','comparaison']).mean()\n",
    "# metrics_means_by_site = metrics_compilation.groupby('site').mean()\n",
    "\n",
    "# print(dists_means_by_site)\n",
    "# print(metrics_means_by_site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # FIX METRICS COMPILATION\n",
    "# directory = os.path.join(MAINFOLDER, robust_method)\n",
    "# df = pd.read_csv(os.path.join(directory, \"metrics_compilation.csv\"))\n",
    "\n",
    "# # Group by the site\n",
    "# grouped = df.groupby('site')\n",
    "\n",
    "# # Process each site\n",
    "# cleaned_dfs = []\n",
    "# for site, group in grouped:\n",
    "#     # Reset index for easier manipulation\n",
    "#     group = group.reset_index(drop=True)\n",
    "    \n",
    "#     # # The first row is the \"bundle row\" (new column names)\n",
    "#     # new_columns = group.iloc[0].values  # Extract column names from the first row\n",
    "#     # new_columns[-1] = 'site'\n",
    "#     # group = group.iloc[1:]  # Remove the first row\n",
    "    \n",
    "#     # # Assign new column names\n",
    "#     # group.columns = new_columns\n",
    "    \n",
    "#     # # Sort the columns alphabetically (excluding 'site')\n",
    "#     # sorted = group.sort_index(axis=1)\n",
    "#     # Add a new column 'nomm' with the value indicating the metric for each row\n",
    "#     metrics = ['tp', 'fp', 'tn', 'fn', 'precision', 'recall', 'taux_faux_positifs', 'f1_score']\n",
    "#     group['metric'] = metrics\n",
    "    \n",
    "#     # # Append the cleaned DataFrame for this site\n",
    "#     cleaned_dfs.append(group)\n",
    "\n",
    "# # Concatenate all cleaned DataFrames\n",
    "# final_df = pd.concat(cleaned_dfs, ignore_index=True)\n",
    "\n",
    "# # Save or display the result\n",
    "# final_df.to_csv(os.path.join(directory, \"metrics_compilation.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REAL SITES\n",
    "# directory = os.path.join(MAINFOLDER, robust_method)\n",
    "# raw_directory = os.path.join(RAWFOLDER, site_group)\n",
    "# for filename in sorted(os.listdir(raw_directory)):\n",
    "#     f = os.path.join(raw_directory, filename)\n",
    "#     # checking if it is a file\n",
    "#     if os.path.isfile(f):\n",
    "#         analyse_site(f, robust_method, directory)\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
