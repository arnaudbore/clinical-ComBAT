{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTS and UTILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "from math import sqrt\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "from robust_evaluation_tools.robust_utils import get_complete_combination, get_metrics, get_diseases\n",
    "from robust_evaluation_tools.robust_outlier_detection import find_outliers, analyze_detection_performance\n",
    "from robust_evaluation_tools.synthectic_sites_generations import generate_sites\n",
    "from robust_evaluation_tools.robust_analysis import calculate_precision_by_bundle\n",
    "from clinical_combat.harmonization.QuickCombat import QuickCombat\n",
    "\n",
    "all_metrics = get_metrics()\n",
    "all_diseases = get_diseases(True)\n",
    "\n",
    "MAINFOLDER = \"RESULTS/DISTRIBUTION_ANALYSIS\"\n",
    "SYNTHETIC_SITES = f\"{MAINFOLDER}/SYNTHETIC_SITES\"\n",
    "\n",
    "ANALYSIS_FOLDER = \"ANALYSIS\"\n",
    "\n",
    "raw_directory = os.path.join('DONNES', 'COMPILATIONS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour calculer la divergence KL\n",
    "def kl_divergence(p, q):\n",
    "    return entropy(p, q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXECUTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AFFICHE LES SCATTER PLOTS AU LIEU DES DISTRIBUZTIONS\n",
    "\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Assuming 'HC' is a specific value in the 'disease' column that indicates healthy controls\n",
    "# HC_LABEL = 'HC'\n",
    "\n",
    "# # Plot distribution for each bundle\n",
    "# for disease in all_diseases:\n",
    "#     combination = pd.read_csv(os.path.join(raw_directory, f'{disease}_combination_all_metrics_CamCAN.csv.gz'))\n",
    "#     metric_bundles = combination['metric_bundle'].unique()\n",
    "#     for metric_bundle in metric_bundles:\n",
    "#         subset_all = combination[combination['metric_bundle'] == metric_bundle]\n",
    "#         subset = subset_all[subset_all['old_site'] != 'CamCAN']\n",
    "#         bundle = subset_all.bundle.unique()[0]\n",
    "#         metric = subset_all.metric.unique()[0]\n",
    "#         camCan_subset = subset_all[subset_all['old_site'] == 'CamCAN']\n",
    "        \n",
    "#         # Scatter plot with mean\n",
    "#         plt.figure(figsize=(10, 6))\n",
    "#         plt.scatter(subset[subset['disease'] == HC_LABEL]['age'], subset[subset['disease'] == HC_LABEL]['mean'], color='blue', label='HC', alpha=0.5)\n",
    "#         plt.scatter(camCan_subset['age'], camCan_subset['mean'], color='green', label='CamCAN', alpha=0.5)\n",
    "#         plt.scatter(subset[subset['disease'] != HC_LABEL]['age'], subset[subset['disease'] != HC_LABEL]['mean'], color='red', label=f'{disease}', alpha=0.5)\n",
    "        \n",
    "#         plt.title(f'Distribution of {disease} in metric {metric} for bundle: {bundle} (mean)')\n",
    "#         plt.xlabel('Age')\n",
    "#         plt.ylabel('Mean')\n",
    "#         plt.legend()\n",
    "#         plt.show()\n",
    "        \n",
    "#         # Scatter plot with mean_no_cov\n",
    "#         plt.figure(figsize=(10, 6))\n",
    "#         plt.scatter(subset[subset['disease'] == HC_LABEL]['age'], subset[subset['disease'] == HC_LABEL]['mean_no_cov'], color='blue', label='HC', alpha=0.5)\n",
    "#         plt.scatter(camCan_subset['age'], camCan_subset['mean_no_cov'], color='green', label='CamCAN', alpha=0.5)\n",
    "#         plt.scatter(subset[subset['disease'] != HC_LABEL]['age'], subset[subset['disease'] != HC_LABEL]['mean_no_cov'], color='red', label=f'{disease}', alpha=0.5)\n",
    "        \n",
    "#         plt.title(f'Distribution of {disease} in metric {metric} for bundle: {bundle} (mean_no_cov)')\n",
    "#         plt.xlabel('Age')\n",
    "#         plt.ylabel('Mean_no_cov')\n",
    "#         plt.legend()\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming 'HC' is a specific value in the 'disease' column that indicates healthy controls\n",
    "HC_LABEL = 'HC'\n",
    "DISTRIBUTION_FOLDER = os.path.join(MAINFOLDER, 'COMPILATION_DISTRIBUTION')\n",
    "os.makedirs(DISTRIBUTION_FOLDER, exist_ok=True)\n",
    "\n",
    "def process_disease(disease, raw_directory, DISTRIBUTION_FOLDER):\n",
    "    print(f\"Processing {disease}...\")  # Debugging info\n",
    "    combination = pd.read_csv(os.path.join(raw_directory, f'{disease}_combination_all_metrics_CamCAN.csv.gz'))\n",
    "    metric_bundles = combination['metric_bundle'].unique()\n",
    "    \n",
    "    for metric_bundle in metric_bundles:\n",
    "        subset_all = combination[combination['metric_bundle'] == metric_bundle]\n",
    "        subset = subset_all[subset_all['old_site'] != 'CamCAN']\n",
    "        \n",
    "        bundle = subset_all.bundle.unique()[0]\n",
    "        metric = subset_all.metric.unique()[0]\n",
    "        camCan_subset = subset_all[subset_all['old_site'] == 'CamCAN']\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.kdeplot(subset[subset['disease'] == HC_LABEL]['mean_no_cov'], color='blue', label='HC', fill=True)\n",
    "        sns.kdeplot(camCan_subset['mean_no_cov'], color='green', label='CamCAN', fill=True)\n",
    "        sns.kdeplot(subset[subset['disease'] != HC_LABEL]['mean_no_cov'], color='red', label=f'{disease}', fill=True)\n",
    "        plt.title(f'Distribution of {disease} in metric {metric} for bundle: {bundle}')\n",
    "        plt.xlabel('mean_no_cov')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.legend()\n",
    "\n",
    "        output_dir = os.path.join(DISTRIBUTION_FOLDER, disease, metric)\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        # Save the plot\n",
    "        output_path = os.path.join(output_dir, f'{metric_bundle}.png')\n",
    "        plt.savefig(output_path)\n",
    "        plt.close()\n",
    "\n",
    "# Run diseases in parallel, but keep metric bundles sequential\n",
    "Parallel(n_jobs=-1)(\n",
    "    delayed(process_disease)(disease, raw_directory, DISTRIBUTION_FOLDER)\n",
    "    for disease in all_diseases\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming 'HC' is a specific value in the 'disease' column that indicates healthy controls\n",
    "HC_LABEL = 'HC'\n",
    "\n",
    "# Function to process one disease\n",
    "def process_disease(disease, raw_directory):\n",
    "    print(f\"Processing {disease}...\")  # Debugging info\n",
    "    results = []\n",
    "    \n",
    "    # Load the data for the disease\n",
    "    combination = pd.read_csv(os.path.join(raw_directory, f'{disease}_combination_all_metrics_CamCAN.csv.gz'))\n",
    "    metric_bundles = combination['metric_bundle'].unique()\n",
    "    \n",
    "    for metric_bundle in metric_bundles:\n",
    "        subset_all = combination[combination['metric_bundle'] == metric_bundle]\n",
    "        bundle = subset_all.bundle.unique()[0]\n",
    "        metric = subset_all.metric.unique()[0]\n",
    "\n",
    "        # Subsets for HC and non-HC\n",
    "        hc_data = subset_all[subset_all['disease'] == HC_LABEL]['mean_no_cov'].dropna()\n",
    "        non_hc_data = subset_all[subset_all['disease'] != HC_LABEL]['mean_no_cov'].dropna()\n",
    "\n",
    "        # Ensure both distributions are not empty\n",
    "        if len(hc_data) > 1 and len(non_hc_data) > 1:\n",
    "            # Create histograms to normalize distributions\n",
    "            hc_hist, bins = np.histogram(hc_data, bins=50, density=True)\n",
    "            non_hc_hist, _ = np.histogram(non_hc_data, bins=bins, density=True)\n",
    "\n",
    "            # Compute metrics\n",
    "            mean_hc = np.mean(hc_data)\n",
    "            mean_non_hc = np.mean(non_hc_data)\n",
    "            std_hc = np.std(hc_data)\n",
    "            std_non_hc = np.std(non_hc_data)\n",
    "            var_hc = np.var(hc_data, ddof=1)\n",
    "            var_non_hc = np.var(non_hc_data, ddof=1)\n",
    "            n_hc = len(hc_data)\n",
    "            n_non_hc = len(non_hc_data)\n",
    "\n",
    "            # Pooled standard deviation\n",
    "            pooled_std = abs(np.sqrt(((n_hc - 1) * var_hc + (n_non_hc - 1) * var_non_hc) / (n_hc + n_non_hc - 2)))\n",
    "\n",
    "            # Compute distance metrics\n",
    "            bhatt_dist = QuickCombat.bhattacharyya_distance(hc_data, non_hc_data)\n",
    "            kl_div = kl_divergence(hc_hist + 1e-10, non_hc_hist + 1e-10)  # Add epsilon to avoid division by zero\n",
    "            euclidean_dist = abs(mean_hc - mean_non_hc)\n",
    "            mahalanobis_dist = abs(mean_hc - mean_non_hc) / sqrt((std_hc**2 + std_non_hc**2) / 2)\n",
    "            d_cohen = abs(mean_hc - mean_non_hc) / pooled_std\n",
    "\n",
    "            # Store results\n",
    "            results.append({\n",
    "                'disease': disease,\n",
    "                'metric_bundle': metric_bundle,\n",
    "                'bundle': bundle,\n",
    "                'metric': metric,\n",
    "                'bhattacharyya_distance': bhatt_dist,\n",
    "                'kl_divergence': kl_div,\n",
    "                'euclidean_distance': euclidean_dist,\n",
    "                'mahalanobis_distance': mahalanobis_dist,\n",
    "                'prct_distance': abs(euclidean_dist / mean_hc),\n",
    "                'd_cohen': d_cohen\n",
    "            })\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# Run diseases in parallel, but keep metric bundles sequential\n",
    "all_results = Parallel(n_jobs=-1)(\n",
    "    delayed(process_disease)(disease, raw_directory)\n",
    "    for disease in all_diseases\n",
    ")\n",
    "\n",
    "# Flatten results\n",
    "results = [item for sublist in all_results for item in sublist]\n",
    "\n",
    "# Convert results into DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save results\n",
    "output_dir = MAINFOLDER\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, 'distance_metrics_results.csv')\n",
    "results_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Results saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation du DataFrame de résultat pour les valeurs maximales\n",
    "max_results = []\n",
    "\n",
    "output_path = f'{MAINFOLDER}/distance_metrics_results.csv'\n",
    "results_df = pd.read_csv(output_path)\n",
    "\n",
    "# Parcourir chaque maladie\n",
    "for disease in results_df['disease'].unique():\n",
    "    disease_subset = results_df[results_df['disease'] == disease]\n",
    "    \n",
    "    # Identifier les metric_bundles avec les valeurs maximales pour chaque mesure de distance\n",
    "    max_bhatt = disease_subset.loc[disease_subset['bhattacharyya_distance'].idxmax()]\n",
    "    max_kl = disease_subset.loc[disease_subset['kl_divergence'].idxmax()]\n",
    "    max_euclidean = disease_subset.loc[disease_subset['euclidean_distance'].idxmax()]\n",
    "    max_mahalanobis = disease_subset.loc[disease_subset['mahalanobis_distance'].idxmax()]\n",
    "    \n",
    "    # Ajouter les résultats dans une liste\n",
    "    max_results.append({\n",
    "        'disease': disease,\n",
    "        'metric_bundle_max_bhatt': max_bhatt['metric_bundle'],\n",
    "        'bhattacharyya_distance': max_bhatt['bhattacharyya_distance'],\n",
    "        'metric_bundle_max_kl': max_kl['metric_bundle'],\n",
    "        'kl_divergence': max_kl['kl_divergence'],\n",
    "        'metric_bundle_max_euclidean': max_euclidean['metric_bundle'],\n",
    "        'euclidean_distance': max_euclidean['euclidean_distance'],\n",
    "        'metric_bundle_max_mahalanobis': max_mahalanobis['metric_bundle'],\n",
    "        'mahalanobis_distance': max_mahalanobis['mahalanobis_distance']\n",
    "    })\n",
    "\n",
    "# Convertir les résultats en DataFrame\n",
    "max_results_df = pd.DataFrame(max_results)\n",
    "\n",
    "# Afficher les résultats\n",
    "print(max_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df\n",
    "results_df = results_df[~results_df['bundle'].isin(['left_ventricle', 'right_ventricle'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output directory\n",
    "column = 'prct_distance'\n",
    "\n",
    "output_dir = f'{MAINFOLDER}/PRCT_HISTOGRAMS/{column}/PER_METRIC'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Parcourir chaque maladie\n",
    "for disease in results_df['disease'].unique():\n",
    "    disease_subset = results_df[results_df['disease'] == disease]\n",
    "    \n",
    "    # Parcourir chaque metric\n",
    "    for metric in disease_subset['metric'].unique():\n",
    "        metric_subset = disease_subset[disease_subset['metric'] == metric]\n",
    "        \n",
    "        # Afficher l'histogramme de la distribution de prct_distance\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.hist(metric_subset[column], bins=30, alpha=0.7, color='blue', edgecolor='black')\n",
    "        plt.title(f'Distribution of {column} for {disease} - {metric}')\n",
    "        plt.xlabel(f'{column}')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.grid(True)\n",
    "        \n",
    "        # Create the directory for the disease and metric\n",
    "        disease_dir = os.path.join(output_dir, disease)\n",
    "        os.makedirs(disease_dir, exist_ok=True)\n",
    "        \n",
    "        # Save the plot\n",
    "        output_path = os.path.join(disease_dir, f'{disease}_{metric}_{column}_histogram.png')\n",
    "        plt.savefig(output_path)\n",
    "        plt.close()# Define the output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output directory\n",
    "output_dir = f'{MAINFOLDER}/PRCT_HISTOGRAMS/{column}/PER_DISEASE'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Parcourir chaque maladie\n",
    "for disease in results_df['disease'].unique():\n",
    "    disease_subset = results_df[results_df['disease'] == disease]  \n",
    "    # Afficher l'histogramme de la distribution de prct_distance\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(disease_subset[column], bins=30, alpha=0.7, color='blue', edgecolor='black')\n",
    "    plt.title(f'Distribution of {column} for {disease} -')\n",
    "    plt.xlabel(f'{column}')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Save the plot\n",
    "    output_path = os.path.join(output_dir, f'{disease}__{column}_histogram.png')\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = f'{MAINFOLDER}/PRCT_HISTOGRAMS/{column}/PER_METRIC_ALL'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Récupérer la liste unique des metrics\n",
    "all_metrics = results_df['metric'].unique()\n",
    "\n",
    "# Boucle sur chaque metric\n",
    "for metric in all_metrics:\n",
    "    # Filtrer le DataFrame sur le metric courant\n",
    "    metric_subset = results_df[results_df['metric'] == metric]\n",
    "    \n",
    "    # Créer une figure\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Récupérer la liste unique des maladies pour ce metric\n",
    "    all_diseases = metric_subset['disease'].unique()\n",
    "    \n",
    "    # Pour chaque maladie, tracer l’histogramme de prct_distance\n",
    "    for disease in all_diseases:\n",
    "        disease_subset = metric_subset[metric_subset['disease'] == disease]\n",
    "        plt.hist(\n",
    "            disease_subset[column], \n",
    "            bins=30, \n",
    "            alpha=0.5, \n",
    "            label=disease, \n",
    "            edgecolor='black'\n",
    "        )\n",
    "    \n",
    "    # Ajouter légende et titres\n",
    "    plt.title(f'Distribution de prct_distance pour le metric : {metric}')\n",
    "    plt.xlabel(f'{column}')\n",
    "    plt.ylabel('Fréquence')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Enregistrer la figure\n",
    "    output_path = os.path.join(output_dir, f'{metric}_all_diseases_{column}_histogram.png')\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = f'{MAINFOLDER}/PRCT_HISTOGRAMS/{column}'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "# Boucle sur chaque metric\n",
    "    \n",
    "# Créer une figure\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Récupérer la liste unique des maladies pour ce metric\n",
    "all_diseases = results_df['disease'].unique()\n",
    "\n",
    "# Pour chaque maladie, tracer l’histogramme de prct_distance\n",
    "for disease in all_diseases:\n",
    "    disease_subset = results_df[results_df['disease'] == disease]\n",
    "    plt.hist(\n",
    "        disease_subset[column], \n",
    "        bins=30, \n",
    "        alpha=0.5, \n",
    "        label=disease, \n",
    "        edgecolor='black'\n",
    "    )\n",
    "\n",
    "# Ajouter légende et titres\n",
    "plt.title(f'Distribution de {column} pour le metric : {metric}')\n",
    "plt.xlabel('prct_distance')\n",
    "plt.ylabel('Fréquence')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Enregistrer la figure\n",
    "output_path = os.path.join(output_dir, f'all_diseases_{column}_histogram.png')\n",
    "plt.savefig(output_path)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subset of diseases where the string starts with 'SYN'\n",
    "syn_diseases = [\"SYN_0.5\", \"SYN_1\",]\n",
    "output_dir = f'{MAINFOLDER}/PRCT_HISTOGRAMS/{column}/PER_METRIC_WITH_SYN'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Parcourir chaque maladie\n",
    "for disease in all_diseases:\n",
    "    disease_subset = results_df[results_df['disease'] == disease]\n",
    "    \n",
    "    # Parcourir chaque metric\n",
    "    for metric in disease_subset['metric'].unique():\n",
    "        metric_subset = disease_subset[disease_subset['metric'] == metric]\n",
    "        \n",
    "        # Afficher l'histogramme de la distribution de prct_distance\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        for dis in syn_diseases:\n",
    "            syn_sub = results_df[results_df['disease'] == dis]\n",
    "            syn_met = syn_sub[syn_sub['metric'] == metric]\n",
    "            plt.hist(\n",
    "                syn_met[column], \n",
    "                bins=30, \n",
    "                alpha=0.2, \n",
    "                label=dis, \n",
    "                edgecolor='black'\n",
    "            )\n",
    "        plt.hist(metric_subset[column], bins=30, alpha=0.7, color='blue', edgecolor='black', label=disease)\n",
    "        plt.title(f'Distribution of {column} for {disease} - {metric}')\n",
    "        plt.xlabel(f'{column}')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "        # Pour chaque maladie, tracer l’histogramme de prct_distance\n",
    "        \n",
    "        # Create the directory for the disease and metric\n",
    "        disease_dir = os.path.join(output_dir, disease)\n",
    "        os.makedirs(disease_dir, exist_ok=True)\n",
    "        \n",
    "        # Save the plot\n",
    "        output_path = os.path.join(disease_dir, f'{disease}_{metric}_{column}_histogram.png')\n",
    "        plt.savefig(output_path)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_path = 'RESULTS/DISTRIBUTION_RESULTS/distance_metrics_results.csv'\n",
    "# distance_metrics_results = pd.read_csv(output_path)\n",
    "\n",
    "# average_results = distance_metrics_results.groupby(['disease', 'metric']).mean(numeric_only=True).reset_index()\n",
    "# average_results\n",
    "# highest_lowest_metrics = average_results.groupby('disease').agg(\n",
    "#     highest_bhattacharyya=('bhattacharyya_distance', lambda x: average_results.loc[x.idxmax(), 'metric']),\n",
    "#     lowest_bhattacharyya=('bhattacharyya_distance', lambda x: average_results.loc[x.idxmin(), 'metric']),\n",
    "#     highest_kl=('kl_divergence', lambda x: average_results.loc[x.idxmax(), 'metric']),\n",
    "#     lowest_kl=('kl_divergence', lambda x: average_results.loc[x.idxmin(), 'metric']),\n",
    "#     highest_euclidean=('euclidean_distance', lambda x: average_results.loc[x.idxmax(), 'metric']),\n",
    "#     lowest_euclidean=('euclidean_distance', lambda x: average_results.loc[x.idxmin(), 'metric']),\n",
    "#     highest_mahalanobis=('mahalanobis_distance', lambda x: average_results.loc[x.idxmax(), 'metric']),\n",
    "#     lowest_mahalanobis=('mahalanobis_distance', lambda x: average_results.loc[x.idxmin(), 'metric'])\n",
    "# ).reset_index()\n",
    "\n",
    "# highest_lowest_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_path = 'RESULTS/DISTRIBUTION_RESULTS/distance_metrics_results.csv'\n",
    "# distance_metrics_results = pd.read_csv(output_path)\n",
    "\n",
    "# # Find the bundle/metric with the highest and lowest value for each distance metric for each disease\n",
    "# highest_lowest_values = distance_metrics_results.groupby('disease').agg(\n",
    "#     highest_bhattacharyya=('bhattacharyya_distance', lambda x: distance_metrics_results.loc[x.idxmax(), 'metric_bundle']),\n",
    "#     lowest_bhattacharyya=('bhattacharyya_distance', lambda x: distance_metrics_results.loc[x.idxmin(), 'metric_bundle']),\n",
    "#     highest_kl=('kl_divergence', lambda x: distance_metrics_results.loc[x.idxmax(), 'metric_bundle']),\n",
    "#     lowest_kl=('kl_divergence', lambda x: distance_metrics_results.loc[x.idxmin(), 'metric_bundle']),\n",
    "#     highest_euclidean=('euclidean_distance', lambda x: distance_metrics_results.loc[x.idxmax(), 'metric_bundle']),\n",
    "#     lowest_euclidean=('euclidean_distance', lambda x: distance_metrics_results.loc[x.idxmin(), 'metric_bundle']),\n",
    "#     highest_mahalanobis=('mahalanobis_distance', lambda x: distance_metrics_results.loc[x.idxmax(), 'metric_bundle']),\n",
    "#     lowest_mahalanobis=('mahalanobis_distance', lambda x: distance_metrics_results.loc[x.idxmin(), 'metric_bundle'])\n",
    "# ).reset_index()\n",
    "\n",
    "# highest_lowest_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    disease metric                       bundle   d_cohen\n",
      "0        AD    adt               adt_mni_IFOF_R  0.191462\n",
      "1        AD    adt  adt_mni_IIT_mask_skeletonFA  0.296575\n",
      "2        AD    adt                adt_mni_ICP_R  0.312118\n",
      "3        AD     rd                 rd_mni_ICP_R  0.200502\n",
      "4        AD     rd                 rd_mni_ICP_L  0.248057\n",
      "..      ...    ...                          ...       ...\n",
      "295  SYN_-1     fw                   fw_mni_MCP  1.000150\n",
      "296  SYN_-1     fw                  fw_mni_UF_L  1.000165\n",
      "297  SYN_-1    fat                fat_mni_STT_L  1.000055\n",
      "298  SYN_-1    fat                fat_mni_ICP_L  1.000060\n",
      "299  SYN_-1    fat                  fat_mni_MCP  1.000061\n",
      "\n",
      "[300 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "output_path = f'{MAINFOLDER}/distance_metrics_results.csv'\n",
    "results_df = pd.read_csv(output_path)\n",
    "# Create a DataFrame to store the results\n",
    "top_3_smallest_d_cohen = []\n",
    "\n",
    "# Iterate over each disease\n",
    "for disease in results_df['disease'].unique():\n",
    "    disease_subset = results_df[results_df['disease'] == disease]\n",
    "    \n",
    "    # Iterate over each metric\n",
    "    for metric in disease_subset['metric'].unique():\n",
    "        metric_subset = disease_subset[disease_subset['metric'] == metric]\n",
    "        \n",
    "        # Sort by d_cohen and select the top 3 smallest values\n",
    "        smallest_d_cohen = metric_subset.nsmallest(3, 'd_cohen')\n",
    "        \n",
    "        # Add the results to the list\n",
    "        for _, row in smallest_d_cohen.iterrows():\n",
    "            top_3_smallest_d_cohen.append({\n",
    "                'disease': disease,\n",
    "                'metric': metric,\n",
    "                'bundle': row['metric_bundle'],\n",
    "                'd_cohen': row['d_cohen']\n",
    "            })\n",
    "\n",
    "# Convert the results into a DataFrame\n",
    "top_3_smallest_d_cohen_df = pd.DataFrame(top_3_smallest_d_cohen)\n",
    "\n",
    "# Display the results\n",
    "print(top_3_smallest_d_cohen_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   metric     bundle   d_cohen\n",
      "0      ad  mni_ICP_R  0.138507\n",
      "1      ad  mni_ICP_L  0.143599\n",
      "2      ad    mni_MCP  0.190170\n",
      "3     adt  mni_ICP_R  0.140043\n",
      "4     adt  mni_ICP_L  0.146304\n",
      "5     adt    mni_MCP  0.200017\n",
      "6     afd  mni_F_L_R  0.197745\n",
      "7     afd     mni_AC  0.213232\n",
      "8     afd   mni_OR_R  0.213256\n",
      "9      fa   mni_ML_R  0.127405\n",
      "10     fa  mni_STT_R  0.130809\n",
      "11     fa  mni_STT_L  0.136513\n",
      "12    fat  mni_ICP_L  0.174757\n",
      "13    fat  mni_ICP_R  0.179768\n",
      "14    fat    mni_MCP  0.204329\n",
      "15     fw  mni_ICP_L  0.229651\n",
      "16     fw    mni_MCP  0.230657\n",
      "17     fw  mni_AST_R  0.240591\n",
      "18     md  mni_ICP_R  0.146979\n",
      "19     md  mni_ICP_L  0.151578\n",
      "20     md    mni_MCP  0.161687\n",
      "21    mdt  mni_ICP_R  0.144038\n",
      "22    mdt  mni_ICP_L  0.148043\n",
      "23    mdt  mni_CST_R  0.150722\n",
      "24     rd    mni_MCP  0.137880\n",
      "25     rd  mni_ICP_R  0.140330\n",
      "26     rd  mni_CST_R  0.145597\n",
      "27    rdt  mni_ICP_R  0.125416\n",
      "28    rdt  mni_ICP_L  0.136099\n",
      "29    rdt    mni_MCP  0.136748\n"
     ]
    }
   ],
   "source": [
    "# 1. Enlève les maladies SYN\n",
    "filtered_df = results_df[~results_df['disease'].str.startswith('SYN')]\n",
    "\n",
    "# 2. Moyenne de d_cohen pour chaque combinaison metric + bundle\n",
    "mean_dcohen = (\n",
    "    filtered_df\n",
    "    .groupby(['metric', 'bundle'])['d_cohen']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# 3. Top 3 des bundles avec la plus petite moyenne de d_cohen pour chaque metric\n",
    "top3_per_metric = (\n",
    "    mean_dcohen\n",
    "    .sort_values(['metric', 'd_cohen'])\n",
    "    .groupby('metric')\n",
    "    .head(3)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Affichage\n",
    "print(top3_per_metric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       bundle   d_cohen\n",
      "17  mni_ICP_R  0.164943\n",
      "16  mni_ICP_L  0.168220\n",
      "23    mni_MCP  0.185897\n"
     ]
    }
   ],
   "source": [
    "# 1. Toujours filtrer les maladies SYN\n",
    "filtered_df = results_df[~results_df['disease'].str.startswith('SYN')]\n",
    "\n",
    "# 2. Moyenne de d_cohen pour chaque (metric, bundle)\n",
    "mean_dcohen_metric_bundle = (\n",
    "    filtered_df\n",
    "    .groupby(['metric', 'bundle'])['d_cohen']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# 3. Moyenne de d_cohen pour chaque bundle (tous metrics confondus)\n",
    "mean_dcohen_per_bundle = (\n",
    "    mean_dcohen_metric_bundle\n",
    "    .groupby('bundle')['d_cohen']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# 4. Prendre les 3 bundles avec la plus petite moyenne overall\n",
    "top3_bundles_overall = mean_dcohen_per_bundle.nsmallest(3, 'd_cohen')\n",
    "\n",
    "# Afficher le résultat\n",
    "print(top3_bundles_overall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      bundle disease metric   d_cohen\n",
      "0  mni_ICP_L    ADHD    afd  0.515280\n",
      "1  mni_ICP_R    ADHD    afd  0.500354\n",
      "2    mni_MCP    ADHD    afd  0.576823\n"
     ]
    }
   ],
   "source": [
    "# 1. Reprend les 3 meilleurs bundles (si pas déjà dans la variable)\n",
    "top_bundles = top3_bundles_overall['bundle'].tolist()\n",
    "\n",
    "# 2. Filtrer les lignes associées à ces bundles (et exclure SYN)\n",
    "worst_cases = results_df[\n",
    "    (results_df['bundle'].isin(top_bundles)) &\n",
    "    (~results_df['disease'].str.startswith('SYN'))\n",
    "]\n",
    "\n",
    "# 3. Trouver le pire cas pour chaque bundle\n",
    "worst_per_bundle = (\n",
    "    worst_cases.loc[\n",
    "        worst_cases.groupby('bundle')['d_cohen'].idxmax()\n",
    "    ][['bundle', 'disease', 'metric', 'd_cohen']]\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Afficher le résultat\n",
    "print(worst_per_bundle)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
